---
title: "Untitled"
author: '305316390'
date: "22 January 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load packages and functions
```{r}
library(abind)
library(corrplot)
library(numDeriv)
library(matrixcalc)
library(R.matlab)
library(stats4)
library(tidyverse)

#Calculate mean Correlation
calculate_mean_matrix <- function(matrix_array){
  temp <- matrix(0, ncol = dim(matrix_array)[2], nrow = dim(matrix_array)[1])
  returns <- dim(matrix_array)[3]
  for(i in 1:returns) temp <- temp + matrix_array[,,i]
  return(temp/returns)
}

#Calculate non-biased estimates for Mean, Variance, Skewness and (Ex-)Kurtosis
central.moment <- function(x,norm=TRUE) {
  n<-length(x)
  b<-vector()
  
  mean<-mean(x)
  sd<-sqrt(var(x)*((n-1)/n))
  
  b<-c(b,mean)
  b<-c(b,var(x))
  
  skew<-mean((x-mean)^3)/(sd^3)
  kurt<-(mean((x-mean)^4)/(sd^4))
  
  b<-c(b,(sqrt(n*(n-1))/(n-2))*skew)
  b<-c(b,((n-1)/((n-2)*(n-3)))*((n+1)*kurt+6))
  if (norm) b[4]<-b[4]-3
  
  names(b) <- c("Mean", "Variance", "Skewness", "Kurtosis")
  if (norm) names(b)[4]<-"Ex.Kurtosis"
  return(b)
}

#Take array of symmetric matrices and convert them to one data matrix
cor.matrix_to_norm.matrix <- function(ARRAY) t(apply(ARRAY, 3, triangle_to_vector))

#Build the alpha matrix according to the model
create_alpha_mat <- function(VECT){
  pelet <- VECT%*%t(VECT)
  diag(pelet) <- rep(1, length(VECT))
  return(pelet)
}

#Force Positive Definiteness
force_positive_definiteness <- function(MATR, sensitivity = 0.01, homoscedasticity = FALSE){
  if(!is.symmetric.matrix(MATR)) stop("MATR not symmetric")
  alpha_seq <- unique(c(0, seq(0,1, by = sensitivity), 1))
  pelet <- MATR
  if(homoscedasticity){
    if(mean(diag(MATR)) <= 0) stop("Diag mean not positive")
  diag_MATR <- mean(diag(MATR)) * diag(nrow(MATR))
  } else {
    if(any(diag(MATR) <= 0)) stop("Diag not positive")
    diag_MATR <- diag(diag(MATR))
  }

  i <- 1
  while(!is.positive.definite(pelet)){
  pelet <- alpha_seq[i]*diag_MATR + (1 - alpha_seq[i])*MATR
  i <- i+1
  }
  
  if(i == 1) return(list(Matrix = pelet,
                         Alpha = 0)) else return(list(Matrix = pelet,
                                                                   Alpha = alpha_seq[i-1]))
}

#Force symmetry on non-symmetrical matrix
force_symmetry <- function(MATR) return((MATR + t(MATR))/2)

#Calculte sum of mahalonobis distances
SSS_norm.matrix <- function(DATA, mu, sigma, solve_sig = TRUE, reg.par = 0){
  if((reg.par < 0) | (reg.par > 1)) stop("reg.par not between [0,1]")
  sigma <- (1 - reg.par)*sigma + reg.par*mean(diag(sigma))*diag(length(mu))
  
  if(solve_sig) sigma <- solve(sigma)
  dist <- DATA - rep(1,nrow(DATA))%*%t(mu)
  return(sum(diag(dist%*%sigma%*%t(dist))))
}

#Retrieve lower/upper triangle of a matrix as a vector
triangle_to_vector <- function(MATR , diag = FALSE){
  if(nrow(MATR) != ncol(MATR)) stop("Matrix not p x p")
  return(as.vector(MATR[lower.tri(MATR, diag = diag)]))
}

#Trim extreme values
trim_num <- function(x, lower = -Inf, upper = Inf){
  pelet <- x
  pelet[x<lower] <- lower
  pelet[x>upper] <- upper
  return(pelet)
}

#Create a symmetric matrix from a vector
vector_to_triangle <- function(VECT){
  m <- length(VECT)
  p <- 0.5*c(1+sqrt(1+8*m), 1-sqrt(1+8*m))
  p <- p[which( (p==round(p))&p==abs(p) )]
  if(length(p)==0) stop("Vect length does not fit size of triangular matrix")
  pelet <- matrix(0, ncol = p, nrow = p)
  pelet[lower.tri(pelet)] <- VECT
  pelet <- pelet+t(pelet)
  diag(pelet) <- 1
  return(pelet)
}

#Calculate Maholonobis norm of a vector. Default is regular norm.
vnorm <- function(x, MATR = NULL, sqroot = FALSE, solve_matr = FALSE){
  if(solve_matr) MATR <- solve(MATR)
  if(length(MATR)==0) { pelet <- sum(x^2) } else{ pelet <- as.vector(t(x)%*%MATR%*%x) }
  if(sqroot) pelet <- sqrt(pelet)
  return(pelet)
}
```

Set parameters for simulation
```{r}
#Set sample size
healthy_N <- 107
sick_N <- 92
Tlength <- 115
p <- 7 # max{p} = 24
```

Generate real parameters
```{r}
build_parameters <- function(p, percent_alpha, range_alpha, loc_scale = c(0,1), seed = NULL){
  #Build Real Sigma and Theta
  if(length(seed) > 0) set.seed(seed[1])
  temp <- matrix(rnorm(2*p^2, loc_scale[1], loc_scale[2]), nrow = 2*p)
  temp <- t(temp)%*%temp
  real.theta <- force_symmetry(cov2cor(temp))
  
  #Generate Variances and create Variance matrix parameters
  if(length(seed) > 0) set.seed(seed[2])
  varss <- rlogis(p)^2
  real.sigma <- sqrt(diag(varss)) %*% real.theta %*% sqrt(diag(varss))
  
  #Build Real Alpha
  alpha <- rep(1,p)
  if(length(seed) > 0) set.seed(seed[3])
  alpha[sample(1:p, floor(percent_alpha * p))] <- runif(floor(percent_alpha * p), range_alpha[1], range_alpha[2])
  
  return(list(Corr.mat = real.theta, Cov.mat = real.sigma, Alpha = alpha))
}

parameters <- build_parameters(p, 0.4, c(0.85,0.95))
real.theta <- parameters$Corr.mat
real.sigma <- parameters$Cov.mat
alpha <- parameters$Alpha
alpha.mat <- create_alpha_mat(alpha)
rm(parameters)
```

Simulate sample from parameters and estimate
```{r}
#Simulate Sample
create_correlation_matrices <- function(real_corr, sample_size, df = 0, var_scale = NULL,
                                        seed.control = NULL){
  if(!is.positive.definite(real_corr)) stop("real_corr not positive definite")
  p <- nrow(real_corr)
  if((df > 0) & (df <= p + 1)) warning("df <= p + 1, p + 1 used in wishart simulations")
  df <- max(df, p + 1)
  if(length(var_scale)==0){
    var_scale <- runif(p,10,100)
  } else if(length(var_scale)!=p){
    stop("var_scale not in dimension")
  }

  Dhalf <- sqrt(diag(var_scale))
  real_var <- Dhalf%*%real_corr%*%Dhalf

  if(length(seed.control)==1) set.seed(seed.control)
  pelet_matrices <- rWishart(sample_size, df, real_var)
  for(b in 1:sample_size) pelet_matrices[,,b] <- force_symmetry(cov2cor(pelet_matrices[,,b]))
  
  return(pelet_matrices)
}

healthy <- create_correlation_matrices(real.theta, healthy_N, Tlength)
sick <- create_correlation_matrices(real.theta*alpha.mat, sick_N, Tlength)

#Are all matrices positive definite?
all(abind(healthy, sick, along = 3) %>%
      apply(3, is.positive.definite))
```

The Estimation Function on the misspecified model
```{r}
#Estimate Parameters
Estimate.Loop <- function(Healthy_List, Sick_List, MaxLoop = 500, Persic = 5){
  
  Tnai <- all(abind(Healthy_List, Sick_List, along = 3) %>%
            apply(3, is.positive.definite))
  if(!Tnai) stop("Some matrices not positive definite")

  SICK <- Sick_List %>% calculate_mean_matrix() %>% force_symmetry()
  HEALTHY <- Healthy_List %>% calculate_mean_matrix() %>% force_symmetry()
  N <- c(SICK = dim(Sick_List)[3], HEALTHY = dim(Healthy_List)[3])
  p <- dim(Sick_List)[2]
  
  for.optim <- function(ALPHA, THETA) sum(triangle_to_vector(THETA*create_alpha_mat(ALPHA)-SICK)^2)

  #Initialize parameters
  Steps <- list()
  temp.theta <- HEALTHY
  temp.alpha <- optim(rep(0.8,p), function(A) for.optim(A,temp.theta), method = "BFGS")$par
  Steps[[1]] <- list(theta = temp.theta, alpha = temp.alpha)
  
  #Begin Loop until Convergence
  const <- 0
  
  i <- 1
  distanceA <- 100
  distanceT <- 100
  while((i<=MaxLoop)&(distanceA>10^(-Persic))&(distanceT>10^(-Persic))){
    temp.theta <- force_symmetry( (N["SICK"] * SICK / create_alpha_mat(temp.alpha) + 
                                    N["HEALTHY"] * HEALTHY) / sum(N) )
    temp.alpha <- optim(temp.alpha,function(A) for.optim(A,temp.theta), method = "BFGS")$par
    Steps[[i+1]] <- list(theta = temp.theta, alpha = temp.alpha)
    
    distanceA <- vnorm(Steps[[i+1]]$alpha-Steps[[i]]$alpha, sqroot = TRUE)
    distanceT <- vnorm(Steps[[i+1]]$theta-Steps[[i]]$theta, sqroot = TRUE)
    
    if(i%%10==0) cat(paste(i,","))
    i <- i + 1
  }
  
  theta.res <- force_positive_definiteness(temp.theta, sensitivity = 0.0001)
  Estimates <- list(theta = theta.res$Matrix,
                    const = theta.res$Alpha,
                    alpha = temp.alpha)
  
  return(list("Estimates" = Estimates, "Returns" = i, Steps = Steps))
}

Pelet_IID <- Estimate.Loop(healthy, sick, MaxLoop = 100)
```

Build Variance matrix for non-independence model
```{r}
p <- length(alpha)

vector_var_matrix_calc_COR <- function(MATR, nonpositive = c("Stop", "Force", "Ignore"),
                                       reg_par = 0){
  if(length(nonpositive) > 1) nonpositive <- nonpositive[1]
  if(!is.positive.definite(MATR)){
    if(nonpositive == "Force") {MATR <- force_positive_definiteness(MATR)$Matrix
    } else if(nonpositive != "Ignore") stop("MATR not positive definite") }
  
  real.cov2 <- function(i, j, k, l) {
    (MATR[i,j]*MATR[k,l]/2) * (MATR[i,k]^2 + MATR[i,l]^2 + MATR[j,k]^2 + MATR[j,l]^2) -
       MATR[i,j]*(MATR[i,k]*MATR[i,l] + MATR[j,k]*MATR[j,l]) -
      MATR[k,l]*(MATR[i,k]*MATR[j,k] + MATR[i,l]*MATR[j,l]) +
      (MATR[i,k]*MATR[j,l] + MATR[i,l]*MATR[j,k])
    }

  p <- dim(MATR)[1]
  m <- p*(p-1)/2
  
  v1 <- numeric(0)
  v2 <- numeric(0)
  for(i in 1:(p - 1)){
    v1 <- c(v1, rep(i, p - i))
    v2 <- c(v2, (i + 1):p)
  }
  order_vect <- cbind(v1,v2)
  
  pelet <- matrix(nrow = m, ncol = m)
  for(i in 1:m){
    for(j in i:m){
      indexes <- c(order_vect[i,], order_vect[j,])
      pelet[i,j] <- real.cov2(indexes[1], indexes[2], indexes[3], indexes[4])
      pelet[j,i] <- pelet[i,j]
    }
  }
  
  if((reg_par<0)|(reg_par>1)) warning("Regularization Parameter not between 0,1")
  pelet <- (1 - reg_par)*pelet + reg_par*diag(diag(pelet))
  
  return(pelet)
}

emp <- healthy %>% cor.matrix_to_norm.matrix() %>% cov() %>% triangle_to_vector(diag = TRUE)
theo <- healthy %>% calculate_mean_matrix() %>% vector_var_matrix_calc_COR() %>%
  triangle_to_vector(diag = TRUE)

temp_mod <- lm(theo ~ 0 + emp)
round(c("Coef" = temp_mod$coefficients, "Effective_N" = Tlength), 3)

emp2 <- healthy %>% cor.matrix_to_norm.matrix() %>% cov() %>% diag()
theo2 <- healthy %>% calculate_mean_matrix() %>% vector_var_matrix_calc_COR() %>% diag()

temp_mod_diag <- lm(theo2 ~ 0 + emp2)
round(c("Coef" = temp_mod_diag$coefficients, "Effective_N" = Tlength), 3)

data.frame(Theoretical = theo, Empirical = emp) %>% ggplot(aes(x = Theoretical, y = Empirical)) + 
  geom_hline(yintercept = 0) + geom_vline(xintercept = 0) +
  geom_point(col = "blue", alpha = 0.5)
```

Build Likelihood function
```{r}
compute_estimated_N <- function(est, theo){
    x <- triangle_to_vector(theo, diag = TRUE)
    y <- triangle_to_vector(est, diag = TRUE)
    return(lm(x ~ 0 + y)$coef)
}

compute_estimated_N <- function(est, theo){
    x <- diag(theo)
    y <- diag(est)
    return(lm(x ~ 0 + y)$coef)
}

minusloglik <- function(theta, alpha, healthy.data, sick.data, effective.N = NULL, DET = TRUE){
  
  calc_n <- TRUE
  if(length(effective.N) == 2){
    calc_n <- FALSE
    n.effective_H <- effective.N[1]
    n.effective_D <- effective.N[2]
  }
  
  Nh <- nrow(healthy.data)
  Nd <- nrow(sick.data)
  
  g20 <- vector_var_matrix_calc_COR(vector_to_triangle(theta))
  if(calc_n) n.effective_H <- compute_estimated_N(cov(healthy.data), g20)
  e20 <- eigen(g20/n.effective_H)
  U0 <- e20$vectors
  D0 <- e20$values
  
  g21 <- vector_var_matrix_calc_COR(vector_to_triangle(theta)*
                                      create_alpha_mat(alpha))
  if(calc_n) n.effective_D <- compute_estimated_N(cov(sick.data), g21)
  e21 <- eigen(g21/n.effective_H)
  U1 <- e21$vectors
  D1 <- e21$values
  
  
  g10 <- as.matrix(theta)
  g11 <- as.matrix(triangle_to_vector(vector_to_triangle(theta)*create_alpha_mat(alpha)))
  
  dist0 <- (healthy.data - rep(1,Nh)%*%t(g10))%*%U0
  dist1 <- (sick.data - rep(1,Nd)%*%t(g11))%*%U1
  
  SSE <- sum(c(diag(dist0%*%diag(1/D0)%*%t(dist0)), diag(dist1%*%diag(1/D1)%*%t(dist1))))
  if(DET) SSE <- SSE + Nh*sum(log(D0)) + Nd*sum(log(D1))
  
  return(SSE)
}
```

Optimization by iteration method
```{r}
Estimate.Loop2 <- function(theta0, alpha0, Healthy.ARR, Sick.ARR, T_thresh,
                           max.loop = 50, eps = 10^(-3), min_reps = 3, method = "Nelder-Mead",
                           comp_hess = TRUE, progress = TRUE){
  
  compute_estimated_N_2 <- function(sick.data, theta, alpha, threshold){
    return(min( compute_estimated_N(cov(sick.data), vector_var_matrix_calc_COR(
      vector_to_triangle(theta)*create_alpha_mat(alpha))), threshold ))
  }
  minusloglik_onlyalpha <- function(theta, alpha, sick.data, effective.N){
    Nd <- nrow(sick.data)
    meanmat <- vector_to_triangle(theta)*create_alpha_mat(alpha)

    g11 <- as.matrix(triangle_to_vector(meanmat))
    g21 <- vector_var_matrix_calc_COR(meanmat)/effective.N
    eigen21 <- eigen(g21)

    U <- eigen21$vectors
    D <- eigen21$values
    dist <- (sick.data - rep(1,nrow(sick.data))%*%t(g11))%*%U

    return( Nd*sum(log(D)) + sum(diag(dist %*% diag(1/D) %*% t(dist))) )
  }
  
  temp.theta <- theta0
  temp.alpha <- alpha0
  if( !(is.positive.definite(vector_to_triangle(theta0)) &
        is.positive.definite(vector_to_triangle(theta0)*create_alpha_mat(alpha0))) ){
  stop("Initial parameters dont result with positive-definite matrices")
}
  
  healthy.data <- cor.matrix_to_norm.matrix(Healthy.ARR)
  sick.data <- cor.matrix_to_norm.matrix(Sick.ARR)
  healthy_N <- nrow(healthy.data)
  sick_N <- nrow(sick.data)
  p <- dim(Healthy.ARR)[1]
  m <- 0.5*p*(p-1)
  
  Steps <- list()
  Steps[[1]] <- list(theta = temp.theta, alpha = temp.alpha)
  log_optim <- list()
  dist <- 100*eps
  i <- 1
  
  #Convergence is a matrix wich tells us if the convergence in each iteration is completed
  convergence <- rep(-1, max.loop)
  convergence[1] <- 0
  tnai0 <- FALSE
  
  if(progress) cat("\n Progress: 'Loop, (Convergence, Distance);'\n")
  while((i <= max.loop) & (!tnai0)){
    i <- i + 1
    
    effective.N <- compute_estimated_N_2(sick.data, temp.theta, temp.alpha, T_thresh)
    #effective.N <- Tlength
    
    clean_sick <- sick.data/(rep(1, sick_N)
                             %*% t(temp.alpha %>% create_alpha_mat() %>% triangle_to_vector()))
    
    temp.theta <- rbind(healthy.data, clean_sick) %>% colMeans()
  
    #Optimize Alpha
    optim.alpha <- optim(temp.alpha,
                        function(A) minusloglik_onlyalpha(theta = temp.theta,
                                                          alpha = A,
                                                          sick.data = sick.data,
                                                          effective.N = effective.N),
                        method = method,
                        control = list(maxit = min(max(500, i*100), 2000)))
    convergence[i] <- optim.alpha$convergence
    temp.alpha <- optim.alpha$par
    
    Steps[[i]] <- list(theta = temp.theta, alpha = temp.alpha,
                       convergence = optim.alpha$convergence,
                       Est_N = effective.N)
    log_optim[[i]] <- optim.alpha
    
    #KLAL ATZIRA
    #dist <- max(c(sqrt(vnorm(Steps[[i]]$theta - Steps[[i-1]]$theta)/m),
    #              sqrt(vnorm(Steps[[i]]$alpha - Steps[[i-1]]$alpha)/p)))
    dist <- sqrt(mean((Steps[[i]]$alpha - Steps[[i-1]]$alpha)^2))
    
    tnai0 <- FALSE
    if(i > min_reps) tnai0 <- (dist <= eps) & (sum(convergence[i - 0:(min_reps - 1)]) == 0)
    
    if(progress) cat(paste0(i," (",convergence[i],", ",round(dist, 5) , "); "))
  }
  if(comp_hess){
    cat("\n \n 'while' loop finished; Computing Hessian\n")
  
    hess <- hessian(x = temp.alpha,
                    func = function(A) minusloglik_onlyalpha(theta = temp.theta,
                                                             alpha = A,
                                                             sick.data = sick.data,
                                                             effective.N = effective.N))
  } else {hess <- NULL}
  
  return( list(theta = temp.theta, alpha = temp.alpha, Hess = hess, convergence = convergence[1:(min(which(convergence == -1)) - 1)],
               returns = i, Est_N = effective.N, Steps = Steps, Log_Optim = log_optim) )
}

Pelet_Cov <- Estimate.Loop2(theta0 = triangle_to_vector(Pelet_IID$Estimates$theta),
                            alpha0 = Pelet_IID$Estimates$alpha, Healthy.ARR = healthy,
                            Sick.ARR = sick, T_thresh = Tlength, method = "Nelder-Mead")
```

```{r}
minusloglik_onlyalpha <- function(theta, alpha, sick.data, effective.N){

  psi_fun <- function(alpha){
    meanmat <- vector_to_triangle(theta)*create_alpha_mat(alpha)
    g21 <- vector_var_matrix_calc_COR(meanmat)/effective.N
    eigen21 <- eigen(g21, only.values = TRUE)
    return(sum(log(D)))


  }
  Nd <- nrow(sick.data)
  meanmat <- vector_to_triangle(theta)*create_alpha_mat(alpha)
  
  g11 <- as.matrix(triangle_to_vector(meanmat))
  g21 <- vector_var_matrix_calc_COR(meanmat)/effective.N
  eigen21 <- eigen(g21)

  U <- eigen21$vectors
  D <- eigen21$values
  dist <- (sick.data - rep(1,nrow(sick.data))%*%t(g11))%*%U

  return( Nd*sum(log(D)) + sum(diag(dist %*% diag(1/D) %*% t(dist))) )
  }

```

Results
```{r}
build_hyp.test <- function(Estimate.Loop2_object, Real = NULL, test = c("lower", "upper", "two-sided"),
                           qval = 0.05, method = "none", const = 1, effectiveN = NULL){
  if(length(test) > 1) test <- test[1]
  obj <- Estimate.Loop2_object
  
  alpha_var_mat <- solve(obj$Hess)
  alpha_sd <- sqrt(diag(alpha_var_mat))
  
  A <- matrix(nrow = length(obj$alpha), ncol = 6)
  colnames(A) <- c("Est.", "Std.", "Z-val", "P-val", "Adj.P-val", "Reject_H0")
  
  dist_fun <- function(q) pnorm(q)
  if(length(effectiveN) > 0){
    colnames(A)[3] <- "T-val"
    dist_fun <- function(q) pt(q, effectiveN)
  }
  
  A[,1] <- obj$alpha
  A[,2] <- const*alpha_sd
  A[,3] <- (A[,1] - 1)/A[,2]
  
  if(test == "lower"){ A[,4] <- round(dist_fun(A[,3]),5)
  }else if(test == "upper"){ A[,4] <- round(1 - dist_fun(A[,3]),5)
  }else{A[,4] <- round(2*(1-dist_fun(abs(A[,3]))),5)}
  
  A[,5] <- p.adjust(A[,4], method = method)
  A[,6] <- A[,5] < qval
  
  if(length(Real) > 0) A <- cbind(A, Real)
  
  return(list(Results = as.data.frame(A), DF = effectiveN, Test = test, Significance = qval, method = method, SD_origin = alpha_sd, Var_Mat = alpha_var_mat))
}

tmp <- build_hyp.test(Pelet_Cov, alpha, method = "holm", const = 2, effectiveN = Pelet_Cov$Est_N)

Pelet_Cov$returns
Pelet_Cov$convergence
c("Est_DF" = Pelet_Cov$Est_N, "Real_DF" = Tlength)

tmp$Results[order(tmp$Results$Real),]
tmp$DF
tmp$Test
tmp$Significance
tmp$method

healthy.data <- healthy %>% cor.matrix_to_norm.matrix()
sick.data <- sick %>% cor.matrix_to_norm.matrix()


#Do a wilks test (chi-square)
chisq <- -2*( minusloglik(theta = Pelet_Cov$theta,
                          alpha = Pelet_Cov$alpha,
                          healthy.data = healthy.data,
                          sick.data = sick.data) -
                minusloglik(theta = rbind(healthy.data, sick.data) %>% colMeans(),
                            alpha = rep(1, length(Pelet_Cov$alpha)),
                            healthy.data = healthy.data,
                            sick.data = sick.data) )

c("Chisq_val" = chisq, "DF" = length(Pelet_Cov$alpha),
  "Pval" = 1 - pchisq(chisq, length(Pelet_Cov$alpha)))
```

Check Robustness - Carefull, this takes forever.
```{r}
if(p <= 7){
  B <- 100
  simuldat <- list()
  alpha_simul <- matrix(nrow = B, ncol = p)
  
  for (b in 1:B){
    cat(paste0("\n \n b: ", b, ";"))
    healthy_tmp <- create_correlation_matrices(real.theta, healthy_N, Tlength)
    sick_tmp <- create_correlation_matrices(real.theta*alpha.mat, sick_N, Tlength)
    
    res_specified <- Estimate.Loop2(theta0 = triangle_to_vector(Pelet_IID$Estimates$theta),
                                    alpha0 = Pelet_IID$Estimates$alpha,
                                    Healthy.ARR = healthy_tmp, Sick.ARR = sick_tmp, T_thresh = Tlength,
                                    comp_hess = FALSE)
    
    simuldat[[b]] <- list(healthy = healthy_tmp, sick = sick_tmp, specified = res_specified)
    alpha_simul[b,] <- res_specified$alpha
    
  }
  
  Emp_vs_Theo <- data.frame(Theoretic = tmp$SD,
                            Empiric = sapply(1:p, function(i) sd(alpha_simul[,i]))) %>%
    mutate(Quotient = Empiric/Theoretic)
  
  find_covariate <- lm(Empiric ~ 0 + Theoretic, data = Emp_vs_Theo)
  
  hist(Emp_vs_Theo$Quotient, main = "Quotient Histogram", xlab = "Quotient", col = "lightblue")
  summary(Emp_vs_Theo$Quotient)
  
  
  ggplot(Emp_vs_Theo, aes(x = Theoretic, y = Empiric)) +
    geom_abline(slope = 1, intercept = 0, col = "darkblue", size = 1, linetype = 2) +
    geom_abline(slope = find_covariate$coefficients, intercept = 0,
                col = "darkred", size = 1, linetype = 2) + 
    geom_vline(xintercept = 0) + geom_hline(yintercept = 0) + 
    geom_point(col = "black", size = 1.5) + 
    labs(title = "Empiric SD of alpha VS. Theoretical",
         x = "Theoretical SD", y = "Empiric SD")
  summary(find_covariate)
  
  Tlength
  Pelet_Cov$Est_N
  Pelet_Cov$Est_N/Tlength
}
```

Save Enviroment
```{r}
link2 <- paste0("C:/Users/Itamar/Google Drive/Documents/#My Documents/Study/99 Other/Binyamini/Main Work/Data/Enviroments/enviroment ", "p", p, " ", "B", B, " ", gsub(":", "", Sys.time()), ".RData")
save.image(link2)
rm(link2)
```

Check That Damn Coefficient
```{r}
p <- 5
parameters_new <- build_parameters(p, 0.4, c(0.85,0.95))
Tlist <- c(10, 30, 50, 70, 100, 120, 150, 170, 200, 250, 300, 400, 700, 1000, 1500, 2000, 3000, 4000)
lngth_Tlist <- length(Tlist)
B <- 100

alpha_simul <- array(dim = c(B, p, lngth_Tlist))
alpha_sd_est <- matrix(0, nrow = lngth_Tlist, ncol = p)
eff_n <- numeric(lngth_Tlist)

cnt <- 0
for(ti in Tlist){
 cnt <- cnt + 1
 cat("\n DF =", ti, "(", cnt, "/", lngth_Tlist, "):")

  for (b in 1:B){
    isb1 <- (b==1)
    healthy_tmp <- create_correlation_matrices(parameters_new$Corr.mat, healthy_N, ti)
    sick_tmp <- create_correlation_matrices(parameters_new$Corr.mat*create_alpha_mat(parameters_new$Alpha), sick_N, ti)
    
    res_specified <- Estimate.Loop2(theta0 = triangle_to_vector(parameters_new$Corr.mat),
                                    alpha0 = parameters_new$Alpha,
                                    Healthy.ARR = healthy_tmp, Sick.ARR = sick_tmp, T_thresh = ti*10,
                                    comp_hess = isb1, progress = FALSE)
    alpha_simul[b,,cnt] <- res_specified$alpha
    if(isb1){
      alpha_sd_est[cnt,] <- sqrt(diag(solve(res_specified$Hess)))
      eff_n[cnt] <- res_specified$Est_N
      
    }
  if((10*b/B)%%1 == 0) cat(100*b/B, "%, ")
  }
}

emp_sds <- matrix(nrow = lngth_Tlist, ncol = p)
coeffs <- numeric(lngth_Tlist)
for(i in 1:lngth_Tlist) {
  emp_sds[i, ] <- apply(alpha_simul[,,i], 2, sd)
  coeffs[i] <- lm(emp_sds[i,] ~ 0 + alpha_sd_est[i,])$coef
}

tmp <- numeric()
for(i in 1:lngth_Tlist) tmp <- c(tmp, rep(Tlist[i], p))
forplt <- data.frame(DF = factor(tmp), Empiric = as.vector(t(emp_sds)), Estimate = as.vector(t(alpha_sd_est)))
tmp <- rbind(eff_n, round(eff_n/Tlist, 3), coeffs)
colnames(tmp) <- Tlist
row.names(tmp) <- c("Est_n", "Ratio", "Coeffs")
```

Show the Results
```{r}
ggplot(forplt, aes(x = Estimate, y = Empiric, col = DF)) + geom_point() + geom_vline(xintercept = 0) + geom_hline(yintercept = 0) + 
  geom_abline(slope = 1, intercept = 0, size = 0.8, linetype = 2, col = "darkgrey") + 
  #geom_smooth(method = "lm", formula = y ~ 0 + x ,se = FALSE, linetype = 4) + 
  geom_abline(slope = 2, intercept = 0, size = 0.8, col = "darkred", linetype = 2)


data.frame(DF = Tlist, Coefficient = coeffs) %>% ggplot(aes(x = DF, y = Coefficient)) + geom_point() +
  geom_hline(yintercept = 1, col = "darkgrey") + geom_vline(xintercept = 0) + 
  geom_smooth(method = "lm", formula = y ~ log(x), se = FALSE)

#View(t(tmp))
x <- 1/Tlist
summary(lm(coeffs ~ x))

df_error <- tmp[2,]-1
hist(df_error)
summary(df_error)
plot(Tlist, df_error)
summary(lm(df_error ~ 0 + Tlist))
```

Save Enviroment Again
```{r}
link2 <- paste0("C:/Users/Itamar/Google Drive/Documents/#My Documents/Study/99 Other/Binyamini/Main Work/Data/Enviroments/enviroment robustness_check p_",
                p, " T_", lngth_Tlist, " ", gsub(":", "", Sys.time()), ".RData")
save.image(link2)
rm(link2)
```

