#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\begin_modules
algorithm2e
theorems-named
eqs-within-sections
theorems-ams-chap-bytype
todonotes
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Title
\end_layout

\begin_layout Author
Dr.
 Yuval Benjamini, Itamar Faran
\end_layout

\begin_layout Section
Preliminaries
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $X\sim\mathcal{MN}_{T\times p}\left(\boldsymbol{0},\Delta,\Sigma\right)$
\end_inset

, a Matrix Normal RV with Expected Value 0, row-wise Covariance Matrix 
\begin_inset Formula $\underset{T\times T}{\Sigma}$
\end_inset

 and column-wise covariance matrix 
\begin_inset Formula $\underset{p\times p}{\Sigma}$
\end_inset

 and define 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
W & =T^{-1}X^{t}X\\
R & =diag\left(W\right)^{-\nicefrac{1}{2}}\cdot W\cdot diag\left(W\right)^{-\nicefrac{1}{2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Lemma
The Distribution of the Empiric Covariance Matrix 
\begin_inset Formula $W$
\end_inset


\end_layout

\begin_layout Standard
When the rows are independently distributed (
\begin_inset Formula $\Delta=I_{T}$
\end_inset

), 
\begin_inset Formula $W=T^{-1}X^{t}X$
\end_inset

 is the MLE estimate of 
\begin_inset Formula $\Sigma$
\end_inset

.
 Furthermore, 
\begin_inset Formula $T\cdot W\sim W_{p}\left(\Sigma,T\right)$
\end_inset

 with the following two first moments:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
E\left[W\right] & =\Sigma\\
T\cdot Cov\left(W_{ij},W_{kl}\right) & =\Sigma_{ij,kl}^{\left(2\right)}=\Sigma_{ik}\Sigma_{jl}+\Sigma_{il}\Sigma_{jk}
\end{align}

\end_inset


\end_layout

\begin_layout Lemma
The Moments of the Correlation Matrix 
\begin_inset Formula $R$
\end_inset


\end_layout

\begin_layout Standard
The Wishart distribution is closed under convolution (if 
\begin_inset Formula $U\sim W_{p}\left(\Sigma,n\right),V\sim W_{p}\left(\Sigma,m\right)$
\end_inset

, then 
\begin_inset Formula $U+V\sim W_{p}\left(\Sigma,m+n\right)$
\end_inset

), and 
\begin_inset Formula $W$
\end_inset

 itself has a limit distribution of Matrix Normal with 
\begin_inset Formula $W\underset{n\rightarrow\infty}{\overset{d}{\longrightarrow}}\mathcal{MN}_{p\times p}\left(\Sigma,\Sigma^{\left(2\right)}\right)$
\end_inset

 .
 Since The Correlation matrix is a function of 
\begin_inset Formula $W$
\end_inset

 (
\begin_inset Formula $R_{ij}=\frac{W_{ij}}{\sqrt{W_{ii}W_{jj}}}$
\end_inset

), the Delta method can be used to approximate 
\begin_inset Formula $R$
\end_inset

's second moment.
 If we denote 
\begin_inset Formula $\rho_{ij}=\frac{\Sigma_{ij}}{\sqrt{\Sigma_{ii}\Sigma_{jj}}}$
\end_inset

, then our implementation of the method yields:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\underset{n\rightarrow\infty}{\lim}E\left[R\right]=\boldsymbol{\rho}\coloneqq diag\left(\Sigma\right)^{-\nicefrac{1}{2}}\cdot\Sigma\cdot diag\left(\Sigma\right)^{-\nicefrac{1}{2}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\underset{n\rightarrow\infty}{\lim}n\cdot Cov\left(R_{ij},R_{kl}\right)=C_{ij,kl}\left(\boldsymbol{\rho}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
C_{ij,kl}\left(\boldsymbol{\rho}\right)\coloneqq\frac{\boldsymbol{\rho_{ij}}\boldsymbol{\rho_{kl}}}{2}\left(\rho_{ik}^{2}+\rho_{il}^{2}+\rho_{jk}^{2}+\rho_{jl}^{2}\right)-\boldsymbol{\rho_{ij}}\left(\rho_{ik}\rho_{il}+\rho_{jk}\rho_{jl}\right)-\boldsymbol{\rho_{kl}}\left(\rho_{ik}\cdot\rho_{jk}+\rho_{il}\cdot\rho_{jl}\right)+\left(\rho_{ik}\rho_{jl}+\rho_{il}\rho_{jk}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Lemma
The Effective Degrees of Freedom when Row-wise Correlation is Present
\end_layout

\begin_layout Standard
When row-wise correlation is present (
\begin_inset Formula $\Delta\neq I_{T}$
\end_inset

), 
\begin_inset Formula $T\cdot W$
\end_inset

 isn't characterized with a Wishart distribution.
 While 
\begin_inset Formula $W$
\end_inset

 remains unbiased, it's variance is inflated since the effective degrees
 of freedom (the gain of information from each observational unit) decreases.
 It can be shown that 
\begin_inset Formula $T_{eff}=\frac{T}{\left(T-1\right)\psi^{2}+1}$
\end_inset

 is the effective degrees of freedom, where 
\begin_inset Formula $\psi$
\end_inset

 is the RMS Factor (B.
 Efron, QUOTE).
 The expression for 
\begin_inset Formula $Cov\left(W\right)$
\end_inset

 and 
\begin_inset Formula $Cov\text{\left(R\right)}$
\end_inset

 remain the same as described in formulas (), up to replacing 
\begin_inset Formula $T$
\end_inset

 with 
\begin_inset Formula $T_{eff}$
\end_inset

.
\end_layout

\begin_layout Definition
Vectorization of a Correlation Matrix 
\end_layout

\begin_layout Definition
Since 
\begin_inset Formula $R$
\end_inset

 is a correlation matrix, it is symmetrical with all elements on the diagonal
 equal to 1 and can be fully characterized using only one of the triangles.
 We define 
\begin_inset Formula $h:\mathbb{M}_{p}\left(\mathbb{R}\right)\mapsto\mathbb{R}^{m}$
\end_inset

 (where 
\begin_inset Formula $m=\frac{p\left(p-1\right)}{2}$
\end_inset

 is the number of elements over the main diagonal) in order to treat the
 Correlation matrix as a vector.
 For the ease of notation, we will denote 
\begin_inset Formula $\vec{u}\coloneqq h\left(u\right)$
\end_inset

 for the rest of this paper.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
h\left(\left[\begin{array}{cccc}
R_{11} & R_{12} & \cdots & R_{1p}\\
 & R_{22} & \cdots & R_{2p}\\
 &  & \ddots & \vdots\\
 &  &  & R_{pp}
\end{array}\right]\right)=\left(R_{12},R_{13,}\cdots,R_{1p},R_{23},\cdots R_{p-1,p}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Using the lemmas and definition of 
\begin_inset Formula $h$
\end_inset

, we can imply that 
\begin_inset Formula $\vec{R}\rightsquigarrow N_{m}\left(\vec{\boldsymbol{\rho}},n_{eff}^{-1}\cdot\Sigma_{\boldsymbol{\rho}}^{\star}\right)$
\end_inset

 (
\begin_inset Formula $\Sigma_{\boldsymbol{\rho}}^{\star}=\Sigma^{\star}\left(\boldsymbol{\rho}\right)$
\end_inset

)
\end_layout

\begin_layout Section
Non-Linear Modeling of Correlation Matrices
\end_layout

\begin_layout Subsection
Model Definition
\end_layout

\begin_layout Standard
Suppose that the collected data consists of two sets of independent samples,
 denoted by 
\begin_inset Formula $\mathcal{D}$
\end_inset

 and 
\begin_inset Formula $\mathcal{H}$
\end_inset

: diagnosed and control subjects, respectively, each holding 
\begin_inset Formula $n_{d}$
\end_inset

 and 
\begin_inset Formula $n_{h}$
\end_inset

 subjects.
 The observational unit of each subject 
\begin_inset Formula $i$
\end_inset

 is a Correlation matrix 
\begin_inset Formula $R_{i}$
\end_inset

 of dimension 
\begin_inset Formula $p\times p$
\end_inset

 obtained from 
\begin_inset Formula $T$
\end_inset

 measurements.
 We will assume that 
\begin_inset Formula $E\left[R_{i}\right]=\Lambda_{h}$
\end_inset

 for 
\begin_inset Formula $i\in\mathcal{H}$
\end_inset

 and 
\begin_inset Formula $\Lambda_{d}$
\end_inset

 for 
\begin_inset Formula $i\in\mathcal{D}$
\end_inset

.
 In order to estimate and infer on differences between these two matrices,
 on can model both with 
\begin_inset Formula $2m$
\end_inset

 parameters and conduct 
\begin_inset Formula $m$
\end_inset

 Hypotheses test.
 Since this procedure involves a great loss of power by the Multiple-Comparisons
 correction that follows, we seek to model these matrices with less parameters.
 Therefore we model 
\begin_inset Formula $\Lambda_{d}$
\end_inset

 as a function of 
\begin_inset Formula $\Lambda_{h}$
\end_inset

 with a limited number of parameters.
 We define 
\begin_inset Formula $\Lambda_{h}=\Theta$
\end_inset

 and 
\begin_inset Formula $\Lambda_{d}=g\left(\Theta,\alpha\right)$
\end_inset

; 
\begin_inset Formula $\Theta$
\end_inset

 can be seen as the baseline for the study, the behavior of control subjects,
 while 
\begin_inset Formula $\alpha\in\mathbb{\mathbb{M}}_{p\times q}\left(\mathbb{R}\right)$
\end_inset

 is the parameterization of the deviance from the baseline of diagnosed
 subjects.
 
\begin_inset Formula $g:\mathbb{M}_{p}\left(\left[-1,1\right]\right)\mapsto\mathbb{M}_{p}\left(\left[-1,1\right]\right)$
\end_inset

, referred to as the link function, is the parameterization of the relation
 between 
\begin_inset Formula $\Lambda_{h}$
\end_inset

 and 
\begin_inset Formula $\Lambda_{d}$
\end_inset

 in terms of 
\begin_inset Formula $\alpha$
\end_inset

.
 For example, our working example throughout the paper will be 
\begin_inset Formula $g\left(\Theta,\alpha\right)=\Theta\circ\alpha\alpha^{t}$
\end_inset

 (
\begin_inset Formula $\circ$
\end_inset

 denoting the Hadamard product) with 
\begin_inset Formula $q=1$
\end_inset

 - assuming there is a multiplicative relation between 
\begin_inset Formula $\Lambda_{h},\Lambda_{d}$
\end_inset

.
 Another option is 
\begin_inset Formula $g_{ij}\left(\Theta,\alpha\right)=\frac{\Theta_{ij}}{1+\alpha_{i}+\alpha_{j}}$
\end_inset

; The methodology presented in the next sections is generalized for all
 link functions
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Subsection
Model Estimation
\end_layout

\begin_layout Standard
Define 
\begin_inset Formula $Y_{i}=h\left(R_{i}\right)$
\end_inset

, a vectorized correlation matrix of subject 
\begin_inset Formula $i$
\end_inset

.
 By implementing lemma (1-3) and assuming 
\begin_inset Formula $T$
\end_inset

 is relatively large, we assume that 
\begin_inset Formula $Y_{i}\overset{iid}{\sim}N_{m}\left(\vec{g}\left(\Theta,\alpha\right),\nicefrac{\Sigma_{g}^{\star}}{T}\right)$
\end_inset

 for 
\begin_inset Formula $i\in\mathcal{D}$
\end_inset

 where 
\begin_inset Formula $\Sigma_{g}^{\star}$
\end_inset

 is defined as in lemma (), with 
\begin_inset Formula $\vec{g}\left(\Theta,\alpha\right)$
\end_inset

 replacing 
\begin_inset Formula $\mathbf{\rho}$
\end_inset

.
 This allows us to define a full likelihood function:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\ell_{full}=\sum_{i\in\mathcal{H}}\ln\phi_{m}\left(Y_{i},\vec{\Theta},\nicefrac{\Sigma_{\Theta}^{\star}}{T}\right)+\sum_{i\in\mathcal{D}}\ln\phi_{m}\left(Y_{i},\vec{g}\left(\Theta,\alpha\right),\nicefrac{\Sigma_{g}^{\star}}{T}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\phi_{m}$
\end_inset

 is the PDF of an 
\begin_inset Formula $m$
\end_inset

-variate normal RV
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Formula $\left(-2\right)\cdot\ln\phi_{m}\left(x,\mu,\Sigma\right)=Const.+\ln\det\Sigma+\left(x-\mu\right)^{t}\Sigma^{-1}\left(x-\mu\right)$
\end_inset


\end_layout

\end_inset

.
 This optimization tends to reach limiting results: in order to maximize
 the likelihood, a possible solution is to take 
\begin_inset Formula $\alpha\rightarrow\infty$
\end_inset

 (since it's inverted in the weighting matrix 
\begin_inset Formula $\Sigma_{g}^{\star}$
\end_inset

 and in the determinant as well).
 In cases where the link function doesn't fit well to the data, this optimizatio
n method will lead to these limiting results.
 Therefore, we choose to estimate the model's parameters using Generalized
 Estimation Equations methodology.
 Define
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathcal{S}^{\left(h\right)} & =\sum_{i\in\mathcal{H}}\left(Y_{i}-\vec{\Theta}\right)^{t}\overline{\Sigma^{\star}}^{-1}\left(Y_{i}-\vec{\Theta}\right)\\
\mathcal{S}^{\left(d\right)} & =\sum_{i\in\mathcal{D}}\left(Y_{i}-\vec{g}\left(\Theta,\alpha\right)\right)^{t}\overline{\Sigma^{\star}}^{-1}\left(Y_{i}-\vec{g}\left(\Theta,\alpha\right)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\overline{\Sigma^{\star}}^{-1}$
\end_inset

 is estimated independently of 
\begin_inset Formula $\left(\Theta,\alpha\right)$
\end_inset

.
 The Gradient of 
\begin_inset Formula $\mathcal{S}_{d}$
\end_inset

 is 
\begin_inset Formula $\mathbf{J}_{\alpha}g\cdot\overline{\Sigma^{\star}}^{-1}\sum_{i\in\mathcal{D}}\left(Y_{i}-\vec{g}\left(\Theta,\alpha\right)\right)$
\end_inset

 where 
\begin_inset Formula $\mathbf{J}_{\alpha}g$
\end_inset

 is the Jacobian matrix of 
\begin_inset Formula $\vec{g}\left(\Theta,\alpha\right)$
\end_inset

 by 
\begin_inset Formula $\alpha$
\end_inset

.
 By finding the minima of 
\begin_inset Formula $\mathcal{S}_{d}$
\end_inset

, we are finding the solution for 
\begin_inset Formula $\nabla_{\alpha}\mathcal{S}_{d}=0$
\end_inset

 whereas 
\begin_inset Formula $E\left[\nabla_{\alpha}\mathcal{S}_{d}\right]=0$
\end_inset

.
 Thus minimizing 
\begin_inset Formula $\mathcal{S}_{d}$
\end_inset

 can be viewed as a GEE solution.
 Define the following: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\mathcal{S} & =\mathcal{S}^{\left(h\right)}+\mathcal{S}^{\left(d\right)}\\
\hat{\Theta},\hat{\alpha} & =\underset{\Theta.\alpha}{\arg\min}\mathcal{S}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
This solution varies from the ordinary least squares solution by the weighting
 matrix 
\begin_inset Formula $\overline{\Sigma^{\star}}^{-1}$
\end_inset

.
 OLS estimates and inference will yield misspecified variance estimates
 since the columns of 
\begin_inset Formula $Y_{i}$
\end_inset

 aren't independent.
 The GEE method minimizes a weighted least squares equation where distances
 are inversely weighted by their covariance - in our case, we we use the
 covariance structure of 
\begin_inset Formula $Y_{i}$
\end_inset

 defined in lemma ().
 In order to avoid using 
\begin_inset Formula $\alpha$
\end_inset

 in the weight matrix, we use the average correlation matrix to construct
 the estimate of 
\begin_inset Formula $\Sigma^{\star}$
\end_inset

.
 We define 
\begin_inset Formula $\bar{R}_{d}=n_{d}^{-1}\sum_{i\in\mathcal{D}}R_{d}$
\end_inset

 and plug in 
\begin_inset Formula $\Sigma_{\bar{R}_{d}}^{\star}$
\end_inset

 as the weighting matrix in the loss function.
 Given a set of estimates 
\begin_inset Formula $\hat{\Theta}$
\end_inset

, the GEE estimate of 
\begin_inset Formula $\alpha$
\end_inset

 is given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\hat{\alpha}=\underset{\alpha}{\arg\min}\mathcal{S}^{\left(d\right)}=\underset{\alpha}{\arg\min}\sum_{i\in\mathcal{D}}\left(Y_{i}-\vec{g}\left(\hat{\Theta},\alpha\right)\right)^{t}\Sigma_{\bar{R}_{d}}^{\star-1}\left(Y_{i}-\vec{g}\left(\hat{\Theta},\alpha\right)\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The avoidance of a weighting matrix parameterized by 
\begin_inset Formula $\left(\Theta,\alpha\right)$
\end_inset

 also increases the optimization speed and feasibility, among solving the
 challenges raised by the full likelihood model.
 It is also important to note that the value of 
\begin_inset Formula $T_{eff}$
\end_inset

 wasn't needed during the optimization.
 The joint optimization of 
\begin_inset Formula $\mathcal{S}$
\end_inset

 both on 
\begin_inset Formula $\Theta$
\end_inset

 and 
\begin_inset Formula $\alpha$
\end_inset

 is a difficult task and is done iteratively.
 Moreover, since 
\begin_inset Formula $\Theta$
\end_inset

 isn't the parameter of interest, in order to ease computation it is estimated
 using a Moment estimator.
 One would suggest using 
\begin_inset Formula $\bar{R}_{h}=n_{h}^{-1}\sum_{i\in\mathcal{H}}R_{i}$
\end_inset

 , as it is an unbiased estimator of 
\begin_inset Formula $\Theta$
\end_inset

 (IS IT?); however this estimator isn't efficient - it ignores information
 that can be gained from diagnosed subjects.
  An efficient estimator of 
\begin_inset Formula $\Theta$
\end_inset

 must use the information gained by both sets.
 Therefore, given a set of estimators 
\begin_inset Formula $\hat{\alpha}$
\end_inset

, we estimate 
\begin_inset Formula $\Theta$
\end_inset

 with:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\hat{\Theta}=\left(n_{h}+n_{d}\right)^{-1}\left(\sum_{i\in\mathcal{H}}R_{i}+\sum_{i\in\mathcal{D}}g^{-1}\left(R_{i},\hat{\alpha}\right)\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $g^{-1}$
\end_inset

 is the 'reverse' function of 
\begin_inset Formula $g$
\end_inset

.
 In our working example, if 
\begin_inset Formula $g_{ij}\left(\Theta,\alpha\right)=\Theta_{ij}\cdot\alpha_{i}\alpha_{j}$
\end_inset

, then 
\begin_inset Formula $g_{ij}^{-1}\left(R,\alpha\right)=R\cdot\frac{1}{\alpha_{i}\alpha_{j}}$
\end_inset

.
 This is the only restriction on 
\begin_inset Formula $g$
\end_inset

 (beside being differentiable) - that 
\begin_inset Formula $g^{-1}$
\end_inset

 exists.
 Since 
\begin_inset Formula $\hat{\Theta}$
\end_inset

 isn't a linear estimator of 
\begin_inset Formula $\Theta$
\end_inset

, we introduce more bias relative to a simple average of the control subjects;
 However the integration of the 
\begin_inset Formula $n_{d}$
\end_inset

 diagnosed subjects increases it's efficiency.
 Given the two methods described, we define an iterative optimization algorithm
 as described in Algorithm 1
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Solution of GEE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\mathcal{S}_{k}^{\left(d\right)}=\sum_{i\in\mathcal{D}}\left(Y_{i}-\vec{g}\left(\hat{\Theta}_{k},\hat{\alpha}_{k}\right)\right)^{t}\Sigma_{\bar{R}_{d}}^{\star-1}\left(Y_{i}-\vec{g}\left(\hat{\Theta}_{k},\hat{\alpha}_{k}\right)\right)
\]

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\hat{\Theta}_{0}=n_{h}^{-1}\sum_{i\in\mathcal{H}}R_{i}$
\end_inset


\end_layout

\begin_layout Enumerate
While 
\begin_inset Formula $||\mathcal{S}_{k}^{\left(d\right)}-\mathcal{S}_{k-1}^{\left(d\right)}||>\epsilon$
\end_inset

 do:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $\hat{\alpha}_{k}=\underset{\alpha}{\arg\min}\sum_{i\in\mathcal{D}}\left(Y_{i}-\vec{g}\left(\hat{\Theta}_{k-1},\alpha\right)\right)^{t}\Sigma_{\bar{R}_{d}}^{\star-1}\left(Y_{i}-\vec{g}\left(\hat{\Theta}_{k-1},\alpha\right)\right)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\hat{\Theta}_{k}=\left(n_{h}+n_{d}\right)^{-1}\left(\sum_{i\in\mathcal{H}}R_{i}+\sum_{i\in\mathcal{D}}g^{-1}\left(R_{i},\hat{\alpha}_{k}\right)\right)$
\end_inset


\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Subsection
Model Inference
\end_layout

\begin_layout Standard
We use GEE theory to conduct inference on the estimates.
 The variance of 
\begin_inset Formula $\hat{\alpha}$
\end_inset

 is calculated as 
\begin_inset Formula $\widehat{Var}\left(\hat{\alpha}\right)=I^{\left(0\right)-1}I^{\left(1\right)}I^{\left(0\right)-1}$
\end_inset

 where 
\begin_inset Formula $I^{\left(k\right)}=I_{h}^{\left(k\right)}+I_{d}^{\left(k\right)}$
\end_inset

 and:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
I_{d}^{\left(0\right)} & =n_{d}\cdot\frac{\partial\vec{g}\left(\Theta,\alpha\right)}{\partial\alpha}^{t}\cdot\Sigma_{\bar{R}_{d}}^{\star-1}\cdot\frac{\partial\vec{g}\left(\Theta,\alpha\right)}{\partial\alpha}|_{\alpha=\hat{\alpha}}\\
I_{d}^{\left(1\right)} & =n_{d}\cdot\frac{\partial\vec{g}\left(\Theta,\alpha\right)}{\partial\alpha}^{t}\cdot\Sigma_{\bar{R}_{d}}^{\star-1}\cdot\widehat{Cov}_{\mathcal{D}}\cdot\Sigma_{\bar{R}_{h}}^{\star-1}\cdot\frac{\partial\vec{g}\left(\Theta,\alpha\right)}{\partial\alpha}|_{\alpha=\hat{\alpha}}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\widehat{Cov}_{D}=n_{eff}^{-1}\sum_{i\in\mathcal{D}}\left(Y_{i}-\vec{g}\left(\Theta,\alpha\right)\right)\left(Y_{i}-\vec{g}\left(\Theta,\alpha\right)\right)^{t}
\]

\end_inset


\end_layout

\begin_layout Standard
With 
\begin_inset Formula $I_{h}^{\left(0\right)},I_{h}^{\left(1\right)}$
\end_inset

 defined similarly with 
\begin_inset Formula $\vec{\Theta}$
\end_inset

, 
\begin_inset Formula $\Sigma_{\bar{R}_{h}}^{\star-1}$
\end_inset

 replacing 
\begin_inset Formula $\vec{g}\left(\Theta,\alpha\right)$
\end_inset

, 
\begin_inset Formula $\Sigma_{\bar{R}_{d}}^{\star-1}$
\end_inset

.
 There are a couple of interesting notes regarding this estimate; the first
 is the lack of 
\begin_inset Formula $T$
\end_inset

's presence.
 In theory, 
\begin_inset Formula $\Sigma_{\bar{R}_{h}}^{\star}$
\end_inset

 should be divided by 
\begin_inset Formula $T_{eff}$
\end_inset

 in equations (),(); in practice 
\begin_inset Formula $T_{eff}$
\end_inset

 cancels out in the final multiplication of 
\begin_inset Formula $\widehat{Var}\left(\hat{\alpha}\right)$
\end_inset

, and so it is omitted.
 The second is the first appearance of 
\begin_inset Formula $n_{eff}$
\end_inset

: 
\begin_inset Formula $\widehat{Cov}_{D}$
\end_inset

 is the empirical covariance matrix of 
\begin_inset Formula $Y_{i}$
\end_inset

 based on 
\begin_inset Formula $n_{d}$
\end_inset

 independent subjects.
 However, the effective number of subjects is lower than 
\begin_inset Formula $n_{d}$
\end_inset

: 
\series bold
[# Todo: WHY?]
\end_layout

\begin_layout Standard
We estimate 
\begin_inset Formula $n_{eff}$
\end_inset

 using Efron's RMS coefficient estimate 
\begin_inset Formula $\hat{\psi}_{d}=\sqrt{\sum_{i<j}\bar{R}_{d,ij}^{2}/{p \choose 2}}$
\end_inset

 and 
\begin_inset Formula $n_{eff}=\frac{n_{d}}{\left(n_{d}-1\right)\hat{\psi}_{d}^{2}+1}$
\end_inset

 .
 It is also important to note here that 
\begin_inset Formula $\hat{\psi}_{d}$
\end_inset

 is over-estimating the effect of row-wise correlation on the effective
 degrees of freedom; This causes an over-estimation of the variance of 
\begin_inset Formula $\hat{\alpha}$
\end_inset

, resulting with slightly decreased statistical power.
 Although not an optimal solution, this is a better option than failing
 to control the Type-I error that results with under-estimating the variance.
 The third note is the sandwich property of 
\begin_inset Formula $\widehat{Var}\left(\hat{\alpha}\right)$
\end_inset

.
 Under theoretical assumptions, both 
\begin_inset Formula $\nicefrac{\Sigma_{\bar{R}_{d}}^{\star}}{T_{eff}},\widehat{Cov}_{D}\overset{p}{\longrightarrow}\nicefrac{\Sigma_{\Lambda_{d}}^{\star}}{T_{eff}}$
\end_inset

, yielding 
\begin_inset Formula $\Sigma_{\bar{R}_{d}}^{\star-1}\cdot\widehat{Cov}_{D}\cdot\Sigma_{\bar{R}_{h}}^{\star-1}\overset{p}{\longrightarrow}T_{eff}\cdot\Sigma_{\Lambda_{d}}^{\star}$
\end_inset

.
 The usage of the sandwich estimator helps keep the type-I error even when
 asymptotic assumptions fail to hold.
 Finally, we imply that 
\begin_inset Formula $\widehat{Var}\left(\hat{\alpha}\right)^{-\nicefrac{1}{2}}\left(\hat{\alpha}-\alpha\right)\overset{d}{\longrightarrow}N_{pq}\left(0,I_{pq}\right)$
\end_inset

 or 
\begin_inset Formula $\widehat{Var}\left(\hat{\alpha}\right)_{jj}^{-\nicefrac{1}{2}}\left(\hat{\alpha}_{j}-\alpha_{j}\right)\overset{d}{\longrightarrow}0\left(0,1\right)$
\end_inset

 which, in turn, allows us to conduct inference on the estimates 
\begin_inset Formula $\hat{\alpha}$
\end_inset

 with Z-tests.
\end_layout

\begin_layout Standard
The number of hypothesis tests is 
\begin_inset Formula $q$
\end_inset

 (the dimension of 
\begin_inset Formula $\alpha$
\end_inset

) that is controlled by the researcher; the selection of 
\begin_inset Formula $q$
\end_inset

 holds a trade-off between the flexibility of the model and the number of
 hypothesis to test.
 Setting a large 
\begin_inset Formula $q$
\end_inset

 eases the severity of the model assumptions on the data, while setting
 a low value minimizes the number of hypothesis.
 For example, by setting 
\begin_inset Formula $q=1$
\end_inset

, one has only 
\begin_inset Formula $p$
\end_inset

 comparisons, while the most simple model of comparing two averaged correlation
 matrices will end up with 
\begin_inset Formula $m\propto\nicefrac{p^{2}}{2}$
\end_inset

 comparisons.
 Increasing the number of hypothesis reduces the statistical power of the
 research, as a result of adjusting the p-values to control the FDR (or
 FWER); In that sense, our model's advantage is it's ability to preserve
 statistical power by reducing the number of comparisons.
\end_layout

\end_body
\end_document
