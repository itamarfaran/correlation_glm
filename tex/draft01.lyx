#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{caption}
\captionsetup[figure]{textfont=small}
\captionsetup[wrapfigure]{textfont=small}
\end_preamble
\use_default_options true
\begin_modules
algorithm2e
theorems-named
eqs-within-sections
theorems-ams-chap-bytype
todonotes
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement !bh
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style apacann
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Parsimounous Model for Detecting Differences Between Corrrelation-Matrix
 Populations, with Application to Resting State fMRI
\end_layout

\begin_layout Author
Itamar Faran, Yuval Benjamini
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Itemize
scholarly review.
 emphasize that we work on inference
\end_layout

\begin_layout Itemize
introduce our problem - show that we have more power (?)
\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

cartoon
\begin_inset Quotes erd
\end_inset

 of parameters, for example corrplot of theta, corrplot of alpha, visualize
 g
\end_layout

\begin_layout Standard
Resting-state fMRI data is a popular data-collection methodology used for
 characterizing second-order structures in the measured functional brain
 activity.
 In contrast to task-based fMRI, the subject is not asked to participate
 in a psychological task during the scan, and therefore the measured activity
 is not associated with a specific time-locked experimental task.
 Instead, the multiple time-series measuring brain activity are continually
 measured as the subject is resting or performing a continuous cognitive
 task.
 Collapsing the temporal domain, these time-series are summarized into a
 correlation matrix.
\end_layout

\begin_layout Standard
High-dimensional data on relatively few individuals required the development
 of mass-univariate methods for localizing differences.
 In mass-univariate models, univariate statistical tests are performed on
 each regional measurement.
 The resulting tests are then screened using multiplicity correction methods
 to control the probability of getting a non-negligible proportion of false
 positive results in the analysis.
 The detection level, therefore, is affected by the resolution of inference.
 It is therefore important to develop tests that would work on intermediate
 scales: pooling together signals that we expect to be effected by the same
 underlying change, and also reducing the number of tests and the multiplicity
 corrections needed.
 In many cases, however, intermediate-level inference requires elaborate
 accounting of the spatial and correlational structure of the data.
 
\end_layout

\begin_layout Standard
In this work we are interested in characterizing differences in inter-region
 synchronization, summarized as correlation matrices, between neurological
 conditions.
 As our example, we compare summaries of functional MRI brain scans collected
 at rest from patients diagnosed with transient global amnesia [TGA], with
 summaries of scans collected from healthy controls 
\begin_inset CommandInset citation
LatexCommand citep
key "peer2014"
literal "false"

\end_inset

.
 The samples of the patients were all collected within 24 hours of the symptom
 onset.
 In the resting-state fMRI paradigm, multiple channels of brain activity
 are measured at rest, meaning that there are no time-locked experimental
 manipulations.
 The simple demands from the patients make this an effective way to collect
 data from patients as part of the patient intake protocol.
 The most common summary 
\begin_inset CommandInset citation
LatexCommand citep
literal "false"

\end_inset

 is the between-channel correlation matrix, because the mean and variance
 of each channel cannot be recovered from the pre-processing of the signal.
\end_layout

\begin_layout Standard
There are many modern techniques for estimating these differences 
\begin_inset CommandInset citation
LatexCommand citep
literal "false"

\end_inset

, based on regularization, decomposition of the matrices into factors (
\emph on
networks
\emph default
), inference on the inverse matrices (graphical models) and more.
 However, while many of these methods are shown to be consistent, there
 are few tested small-sample inference methods that can provide standard
 deviations or p-values for the detected differences.
 For inference, researchers still need to use mass-univariate approaches,
 conducting 
\begin_inset Formula $m$
\end_inset

 hypotheses tests with multiple-testing and post-selection corrections.
\end_layout

\begin_layout Standard
The researchers are interested in population-level differences in the correlatio
n matrices between the groups.
 For 
\begin_inset Formula $p\in[90,384]$
\end_inset

 regions, let 
\begin_inset Formula $R_{i}$
\end_inset

 be the Pearson correlation matrix summarizing activity for subject 
\begin_inset Formula $i$
\end_inset

.
 (We write 
\begin_inset Formula $R_{i}\in\mathcal{C}_{p}$
\end_inset

,
\begin_inset Formula $\mathcal{C}_{p}$
\end_inset

 is the space of semi-positive definite 
\begin_inset Formula $p\times p$
\end_inset

 symmetric matrix with a diagonal of 1
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Formula $\mathcal{C}_{p}=\left\{ M:M\in\mathbb{M}_{p\times p}\left(\left[-1,1\right]\right),\,M\geq0,\,M_{ii}=1\forall i\right\} $
\end_inset


\end_layout

\end_inset

).
 We model the expected values of 
\begin_inset Formula $R_{i}$
\end_inset

 as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E\left[R_{i}\right]=\begin{cases}
\Lambda^{H} & i\in\mathcal{H}\\
\Lambda^{D} & i\in\mathcal{D}
\end{cases}.
\]

\end_inset

Write 
\begin_inset Formula $m=p(p-1)/2$
\end_inset

 the number of off-diagonal elements.
 Researchers would like to identify pairs 
\begin_inset Formula $i\neq j$
\end_inset

 where 
\begin_inset Formula 
\[
\Lambda_{ij}^{H}-\Lambda_{ij}^{D}\neq0.
\]

\end_inset


\end_layout

\begin_layout Standard
With small clinical samples, however, the mass-univariate approach has very
 little power to detect deviances.
 In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "figure-tga-model-diff"
plural "false"
caps "false"
noprefix "false"

\end_inset

 we show the result of such an analysis produced in 
\begin_inset CommandInset citation
LatexCommand citep
literal "false"

\end_inset

 comparing temporary amnesia patients to healthy controls.
 Here 
\begin_inset Formula $n_{h}$
\end_inset

 and 
\begin_inset Formula $n_{d}$
\end_inset

 are 12 and 17, respectively.
 The individual correlation matrices are noisy due to the relatively short
 time in the magnet (
\begin_inset Formula $T=121$
\end_inset

 or 5 minutes).
 Although relatively strong patterns are observed in many individual locations,
 they are not found to be significant under multiple t-tests.
 In particular, the Hypocampus (region xx) is expected to decay in Amnesia
 patients.
 We observe this decay in correlation is recurrent across multiple regions.
 A simple mechanism can cause this phenomenon: if a single region has less
 cohesive activity in the diagnosed group compared to the control, we expect
 the correlations of the region with most other regions to decay.
 We would therefore want a model that parameterizes each region instead
 of each correlation.
 Inference for such a model would both pull together information and also
 reduce the number of parameters substantially.
\end_layout

\begin_layout Standard
In this paper we propose a parsimonous parameteric model for the difference
 between populations.
 The model tries to formalize the following two assumptions regarding the
 form of change between populations: 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
Assumption: Researchers are interested in identifying regions where the
 correlation profile has changed directionally between the healthy population
 and the patient population (increased or reduced correlation).
 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
Assumption: The expected magnitude of the difference would be proportional
 to the magnitude of the original correlation.
 
\end_layout

\begin_layout Standard
If, for example, the synchronized activity of a single region would be reduced,
 we expect the correlations of that region with all other regions to decay
 toward 0, with the strongest relative decay in the regions originally showing
 the highest correlation.
 We develop from these assumptions a two-way model similar to those used
 for tabular data (
\begin_inset CommandInset citation
LatexCommand citep
literal "false"

\end_inset

), with the added complication that for correlation matrices the rows and
 columns are tied together.
 Letting 
\begin_inset Formula $\Theta=\Lambda_{h}$
\end_inset

 be the mean correlation matrix of the healthy population, we can define
 the mean correlation matrix of the patient population using a vector 
\begin_inset Formula $\alpha\in R^{p}$
\end_inset

 of region parameters, 
\begin_inset Formula $\Lambda_{d}=g(\Theta,\alpha)$
\end_inset

.
 Setting 
\begin_inset Formula 
\[
g(\Theta,\alpha)_{ij}=g_{ij}(\Theta,\alpha)=\Theta_{ij}\cdot\alpha_{i}\alpha_{j},
\]

\end_inset

we get a multiplicative model that codes Assumptions 1+2.
 Here 
\begin_inset Formula $\alpha_{i}<1$
\end_inset

 would represent a decay in the correlations of region 
\begin_inset Formula $i$
\end_inset

 with other regions, and 
\begin_inset Formula $\alpha_{i}>1$
\end_inset

 would represent an increase in those correlations.
 We call 
\begin_inset Formula $g:\mathcal{C}_{p}\mapsto\mathcal{C}_{p}$
\end_inset

 the link function; the specific form of 
\begin_inset Formula $g$
\end_inset

 may vary, and as we find that 
\begin_inset Formula $\tilde{g}_{ij}(\Theta,\alpha)=\frac{\Theta_{ij}}{1+\alpha_{i}+\alpha_{j}}$
\end_inset

 gives very similar results when 
\begin_inset Formula $\alpha_{i}'s$
\end_inset

 are not very far from 1.
\end_layout

\begin_layout Standard
In this manuscript, we propose estimation procedures for both 
\begin_inset Formula $\alpha_{i}$
\end_inset

 and 
\begin_inset Formula $SD(\hat{\alpha}_{i})$
\end_inset

 based on General Estimating Equations (GEE) and the multivariate distribution
 of correlation matrices estimated from Gaussian multivariate time-series
 data with non-trivial row and column correlations.
 The methodology we develop in our preprint is generalized for all link
 functions.
 We develop the covariance of correlation matrices using delta methods,
 and the use assymptotic normality to find the gradient for 
\begin_inset Formula $\alpha$
\end_inset

.
 A particular challenge is computing the degrees-of-freedom for our link
 model.
\end_layout

\begin_layout Section
Preliminaries
\end_layout

\begin_layout Standard
We begin by discussing distributional properties of correlation matrices
 derived from multivariate time-series data.
 Let 
\begin_inset Formula $X$
\end_inset

 be a data matrix measuring the activity of 
\begin_inset Formula $p$
\end_inset

 brain regions (columns) sampled at 
\begin_inset Formula $T$
\end_inset

 time points (rows).
 Assume that 
\begin_inset Formula $X\sim\mathcal{MN}_{T\times p}\left(\boldsymbol{0},\Delta,\Sigma\right)$
\end_inset

, meaning that 
\begin_inset Formula $X$
\end_inset

 follows a multivariate Normal matrix distribution with expected value 
\begin_inset Formula $\boldsymbol{0}$
\end_inset

, row-wise covariance matrix 
\begin_inset Formula $\underset{T\times T}{\Delta}$
\end_inset

, and column-wise covariance matrix 
\begin_inset Formula $\underset{p\times p}{\Sigma}$
\end_inset

.
 Define the empirical covariance operator 
\begin_inset Formula $Cov\left(X\right)=T^{-1}X'X$
\end_inset

, and define the scaling operator on 
\begin_inset Formula $W=Cov\left(X\right)$
\end_inset

 to be 
\begin_inset Formula $scale\left(W\right)=diag\left(W\right)^{-\nicefrac{1}{2}}\cdot W\cdot diag\left(W\right)^{-\nicefrac{1}{2}}$
\end_inset

.
 The empirical correlation operator on 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $X$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit
 is 
\begin_inset Formula $corr\left(X\right)=scale\left(Cov\left(X\right)\right).$
\end_inset

 When the rows are iid (
\begin_inset Formula $\Delta=I_{T}$
\end_inset

), 
\begin_inset Formula $W=Cov\left(X\right)$
\end_inset

 is the maximum likelihood estimator for 
\begin_inset Formula $\Sigma$
\end_inset

 and 
\begin_inset Formula $T\cdot W$
\end_inset

 follows a 
\begin_inset Formula $Wishart_{p}\left(\Sigma,T\right)$
\end_inset

 distribution.
 Importantly for us, the first two moments of 
\begin_inset Formula $W$
\end_inset

 are the following: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
E\left[W\right] & =\Sigma,\\
T\cdot Cov\left(W_{ij},W_{kl}\right) & =\Sigma_{ij,kl}^{\left(2\right)}=\Sigma_{ik}\Sigma_{jl}+\Sigma_{il}\Sigma_{jk},
\end{align}

\end_inset

as shown for example by 
\begin_inset CommandInset citation
LatexCommand cite
key "efron2012large"
literal "false"

\end_inset

.
 However, the elements of empirical correlation matrices have distinctly
 smaller variances because of the scaling.
 The following lemma describes the limiting covariance of values in empirical
 correlation matrices: 
\end_layout

\begin_layout Lemma*
\begin_inset CommandInset label
LatexCommand label
name "lemma-cor-cov"

\end_inset

The asymptotic moments of empirical correlation matrices.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $R=corr(X)$
\end_inset

 for 
\begin_inset Formula $X\sim\mathcal{MN}_{T\times p}\left(\boldsymbol{0},I_{T},\Sigma\right)$
\end_inset

.
 Denote by 
\begin_inset Formula $\rho_{ij}=\frac{\Sigma_{ij}}{\sqrt{\Sigma_{ii}\Sigma_{jj}}}$
\end_inset

.
 Then
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\underset{T\rightarrow\infty}{\lim}E\left[R\right]=diag\left(\Sigma\right)^{-\nicefrac{1}{2}}\cdot\Sigma\cdot diag\left(\Sigma\right)^{-\nicefrac{1}{2}}\eqqcolon\boldsymbol{\rho},
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\underset{T\rightarrow\infty}{\lim}T\cdot Cov\left(R_{ij},R_{kl}\right)=C_{ij,kl}\left(\boldsymbol{\rho}\right),
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
C_{ij,kl}\left(\boldsymbol{\rho}\right)\coloneqq\frac{\boldsymbol{\rho_{ij}}\boldsymbol{\rho_{kl}}}{2}\left(\rho_{ik}^{2}+\rho_{il}^{2}+\rho_{jk}^{2}+\rho_{jl}^{2}\right)-\boldsymbol{\rho_{ij}}\left(\rho_{ik}\rho_{il}+\rho_{jk}\rho_{jl}\right)\label{equation-cor-cov}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
-\boldsymbol{\rho_{kl}}\left(\rho_{ik}\cdot\rho_{jk}+\rho_{il}\cdot\rho_{jl}\right)+\left(\rho_{ik}\rho_{jl}+\rho_{il}\rho_{jk}\right).
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The Delta Method on Correlation Matrices
\begin_inset CommandInset label
LatexCommand label
name "figure-delta-method"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename simulations/correlation_delta_method.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The results rely on the Wishart distribution of 
\begin_inset Formula $W=cov(X)$
\end_inset

 approaching a multi-normal matrix as T increases
\begin_inset Foot
status open

\begin_layout Plain Layout
Since the Wishart distribution is closed under convolution, in the sense
 that if 
\begin_inset Formula $U\sim W_{p}\left(\Sigma,n_{u}\right),V\sim W_{p}\left(\Sigma,n_{v}\right)$
\end_inset

 then 
\begin_inset Formula $U+V\sim W_{p}\left(\Sigma,n_{u}+n_{v}\right)$
\end_inset

, The CLT applies and 
\begin_inset Formula $W$
\end_inset

 has a limit distribution of Matrix Normal
\end_layout

\end_inset

, and applying the Delta-method on the coordinates of correlation matrix
 
\begin_inset Formula $R_{ij}=\frac{W_{ij}}{\sqrt{W_{ii}W_{jj}}}$
\end_inset

.
 We are not aware of these results in the literature, and will give a full
 proof in the supplementary.
 
\end_layout

\begin_layout Standard
In fMRI time-series data, the correlation between adjacent samples can be
 large, and hence the gain of information from each observational unit decreases.
 
\begin_inset Formula $W=Cov(X)$
\end_inset

 remains unbiased, but 
\begin_inset Formula $Var(W)$
\end_inset

 and 
\begin_inset Formula $Var(R)$
\end_inset

 will be inflated compared to equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "equation-cor-cov"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The following correction, due to Efron 
\begin_inset CommandInset citation
LatexCommand cite
key "efron2012large"
literal "false"

\end_inset

, identifies an effective degrees of freedom 
\begin_inset Formula $T_{eff}$
\end_inset

 that can be estimated directly from 
\begin_inset Formula $\Sigma$
\end_inset

.
 We cite the result with no proof.
 
\end_layout

\begin_layout Standard
The Effective Degrees of Freedom: Let 
\begin_inset Formula $X\sim\mathcal{MN}_{T\times p}\left(\boldsymbol{0},\Delta,\Sigma\right)$
\end_inset

 for general positive-definite 
\begin_inset Formula $\Delta$
\end_inset

.
 Define 
\begin_inset Formula $T_{eff}=\frac{T}{\left(T-1\right)\psi^{2}+1}$
\end_inset

 for 
\begin_inset Formula $\psi(\Sigma)$
\end_inset

 the root-mean-square factor 
\begin_inset Formula $\psi=\sum_{i<j}\boldsymbol{\rho}_{ij}^{2}/{p \choose 2}$
\end_inset

.
 Then the covariances of empirical covariance and correlation matrices 
\begin_inset Formula $W$
\end_inset

 and 
\begin_inset Formula $R$
\end_inset

 are as before, with the replacement of 
\begin_inset Formula $T$
\end_inset

 with 
\begin_inset Formula $T_{eff}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
T_{eff}(T,\psi)\cdot Cov\left(W_{ij},W_{kl}\right)=\Sigma_{ij,kl}^{\left(2\right)},
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\underset{T\rightarrow\infty}{\lim}T_{eff}(T,\psi)\cdot Cov\left(R_{ij},R_{kl}\right)=C_{ij,kl}\left(\boldsymbol{\rho}\right).
\]

\end_inset


\end_layout

\begin_layout Standard
Finally, we would like to define the vectorizing operator for correlation
 matrices.
 Correlation matrices can be fully characterized using the 
\begin_inset Formula $m={p \choose 2}=p\cdot(p-1)/2$
\end_inset

 upper triangle elements, because they are symmetric with a degenerate diagonal.
 We define 
\begin_inset Formula $vec:\mathbb{M}_{p}\left(\mathbb{R}\right)\mapsto\mathbb{R}^{m}$
\end_inset

 as the vectorization operator with 
\begin_inset Formula $\text{vec}\left(R\right)=\left(R_{12},R_{13,}\cdots,R_{1p},R_{23},\cdots R_{p-1,p}\right)^{T}.$
\end_inset

 We further denote 
\begin_inset Formula $\vec{u}\coloneqq\text{vec}\left(u\right)$
\end_inset

 for the rest of this paper.
 Using the lemmas and definition of 
\begin_inset Formula $vec$
\end_inset

, we can imply that 
\begin_inset Formula $\vec{R}\rightsquigarrow N_{m}\left(\vec{\boldsymbol{\rho}},T_{eff}^{-1}\cdot\Sigma_{\boldsymbol{\rho}}^{\star}\right)$
\end_inset

 (
\begin_inset Formula $\Sigma_{\boldsymbol{\rho}}^{\star}=\Sigma^{\star}\left(\boldsymbol{\rho}\right)$
\end_inset

 as describe in equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "equation-cor-cov"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\begin_layout Section
Non-Linear Modeling of Correlation Matrices
\end_layout

\begin_layout Subsection
Model Definition
\end_layout

\begin_layout Standard
Suppose that the collected data consists of two sets of independent samples,
 denoted by 
\begin_inset Formula $\mathcal{D}$
\end_inset

 and 
\begin_inset Formula $\mathcal{H}$
\end_inset

: diagnosed and control subjects, respectively, each holding 
\begin_inset Formula $n_{d}$
\end_inset

 and 
\begin_inset Formula $n_{h}$
\end_inset

 subjects.
 The observational unit of each subject 
\begin_inset Formula $i$
\end_inset

 is a Correlation matrix 
\begin_inset Formula $R_{i}$
\end_inset

 of dimension 
\begin_inset Formula $p\times p$
\end_inset

 obtained from 
\begin_inset Formula $T$
\end_inset

 measurements.
 We will assume that 
\begin_inset Formula $E\left[R_{i}\right]=\Lambda_{h}$
\end_inset

 for 
\begin_inset Formula $i\in\mathcal{H}$
\end_inset

 and 
\begin_inset Formula $\Lambda_{d}$
\end_inset

 for 
\begin_inset Formula $i\in\mathcal{D}$
\end_inset

.
 In order to estimate and infer on differences between these two matrices,
 one can model both with 
\begin_inset Formula $2m$
\end_inset

 parameters and conduct 
\begin_inset Formula $m$
\end_inset

 Hypotheses test.
 Since this procedure involves a great loss of power by the Multiple-Comparisons
 correction that follows, we seek to model these matrices with less parameters.
 Therefore we model 
\begin_inset Formula $\Lambda_{d}$
\end_inset

 as a function of 
\begin_inset Formula $\Lambda_{h}$
\end_inset

 with a limited number of parameters.
 We define 
\begin_inset Formula $\Lambda_{h}=\Theta$
\end_inset

 and 
\begin_inset Formula $\Lambda_{d}=g\left(\Theta,\alpha\right)$
\end_inset

; 
\begin_inset Formula $\Theta$
\end_inset

 can be seen as the baseline for the study, the behavior of control subjects,
 while 
\begin_inset Formula $\alpha\in\mathbb{\mathbb{M}}_{p\times q}\left(\mathbb{R}\right)$
\end_inset

 is the parameterization of the deviance from the baseline of diagnosed
 subjects.
 
\begin_inset Formula $g:\mathbb{M}_{p}\left(\left[-1,1\right]\right)\mapsto\mathbb{M}_{p}\left(\left[-1,1\right]\right)$
\end_inset

, referred to as the link function, is the parameterization of the relation
 between 
\begin_inset Formula $\Lambda_{h}$
\end_inset

 and 
\begin_inset Formula $\Lambda_{d}$
\end_inset

 in terms of 
\begin_inset Formula $\alpha$
\end_inset

.
 There are two properties required from 
\begin_inset Formula $g$
\end_inset

; the first is 
\begin_inset Formula $g$
\end_inset

 being differentiable, and the second is the existence of 
\begin_inset Formula $g^{-1}$
\end_inset

, denoting the 'reverse' of 
\begin_inset Formula $g$
\end_inset

 (not necessary it's inverse).
 Our working example throughout the paper will be 
\begin_inset Formula $g\left(\Theta,\alpha\right)=\Theta\circ\alpha\alpha^{t}$
\end_inset

 with 
\begin_inset Formula $q=1$
\end_inset

, '
\begin_inset Formula $\circ$
\end_inset

' denoting the Hadamard product: 
\begin_inset Formula $g_{ij}\left(\Theta,\alpha\right)=\Theta_{ij}\cdot\alpha_{i}\alpha_{j}$
\end_inset

, and a reverse function 
\begin_inset Formula $g_{ij}^{-1}\left(R,\alpha\right)=R\cdot\frac{1}{\alpha_{i}\alpha_{j}}$
\end_inset

.
 This link function relies on the assumption that there is a multiplicative
 relation between 
\begin_inset Formula $\Lambda_{h},\Lambda_{d}$
\end_inset

.
 Another option is 
\begin_inset Formula $g_{ij}\left(\Theta,\alpha\right)=\frac{\Theta_{ij}}{1+\alpha_{i}+\alpha_{j}}$
\end_inset

; The methodology presented in the next sections is generalized for all
 link functions.
\end_layout

\begin_layout Standard
\begin_inset Flex TODO Note (inline)
status open

\begin_layout Plain Layout
Model Identifiability????
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Model Estimation
\begin_inset CommandInset label
LatexCommand label
name "subsec:Model-Estimation"

\end_inset


\end_layout

\begin_layout Standard
Define 
\begin_inset Formula $Y_{i}=vec\left(R_{i}\right)$
\end_inset

, a vectorized correlation matrix of subject 
\begin_inset Formula $i$
\end_inset

.
 By implementing lemma (1-3) and assuming 
\begin_inset Formula $T$
\end_inset

 is relatively large, we assume that 
\begin_inset Formula $Y_{i}\overset{iid}{\sim}N_{m}\left(\vec{g}\left(\Theta,\alpha\right),\Sigma_{g}^{\star}/T\right)$
\end_inset

 for 
\begin_inset Formula $i\in\mathcal{D}$
\end_inset

 where 
\begin_inset Formula $\Sigma_{g}^{\star}=\Sigma^{\star}\left(g\left(\Theta,\alpha\right)\right)$
\end_inset

 is defined as in lemma 
\begin_inset CommandInset ref
LatexCommand vref
reference "lemma-cor-cov"
plural "false"
caps "false"
noprefix "false"

\end_inset

, with 
\begin_inset Formula $g\left(\Theta,\alpha\right)$
\end_inset

 replacing 
\begin_inset Formula $\mathbf{\rho}$
\end_inset

.
 This allows us to define a full log-likelihood function:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\ell_{full}=\sum_{i\in\mathcal{H}}\ln\phi_{m}\left(Y_{i},\vec{\Theta},\Sigma_{\Theta}^{\star}/T\right)+\sum_{i\in\mathcal{D}}\ln\phi_{m}\left(Y_{i},\vec{g}\left(\Theta,\alpha\right),\Sigma_{g}^{\star}/T\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Bias of 
\begin_inset Formula $\hat{\Theta},\hat{\alpha}$
\end_inset


\begin_inset CommandInset label
LatexCommand label
name "figure-bias-static"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename simulations/bias_small_sample.png
	scale 50

\end_inset


\end_layout

\end_inset

 where 
\begin_inset Formula $\phi_{m}$
\end_inset

 is the PDF of an 
\begin_inset Formula $m$
\end_inset

-variate normal RV
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Formula $\left(-2\right)\cdot\ln\phi_{m}\left(x,\mu,\Sigma\right)=Const.+\ln\det\Sigma+\left(x-\mu\right)^{t}\Sigma^{-1}\left(x-\mu\right)$
\end_inset


\end_layout

\end_inset

.
 This optimization might be unstable: in order to maximize the likelihood,
 a possible solution is to take 
\begin_inset Formula $\alpha\rightarrow\infty$
\end_inset

 (since it's inverted in the weighting matrix 
\begin_inset Formula $\Sigma_{g}^{\star}$
\end_inset

 and in the determinant as well).
 In cases where the link function doesn't fit well to the data, this optimizatio
n method will lead to limiting results.
 As a consequence, we look for a solution where the weighting matrix 
\begin_inset Formula $\Sigma^{\star}$
\end_inset

 isn't parameterized with 
\begin_inset Formula $\alpha$
\end_inset

, which leads us to a weighted least squares optimization.
 We use the average correlation matrix to construct an estimate of 
\begin_inset Formula $\Sigma^{\star}$
\end_inset

: we define 
\begin_inset Formula $\bar{R}_{d}=n_{d}^{-1}\sum_{i\in\mathcal{D}}R_{d}$
\end_inset

 and use 
\begin_inset Formula $\bar{\Sigma}_{d}^{\star}=\Sigma^{\star}\left(\bar{R}_{d}\right)$
\end_inset

 as the weighting matrix in the loss function.
 This optimization, that is indifferent to the determinant that appears
 in the Gaussian PDF, yields more stable results than the full log-likelihood
 model.
 Define the following loss functions:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathcal{S}^{\left(h\right)} & =\sum_{i\in\mathcal{H}}\left(Y_{i}-\vec{\Theta}\right)^{t}\bar{\Sigma}_{h}^{\star-1}\left(Y_{i}-\vec{\Theta}\right)\\
\mathcal{S}^{\left(d\right)} & =\sum_{i\in\mathcal{D}}\left(Y_{i}-\vec{g}\left(\Theta,\alpha\right)\right)^{t}\bar{\Sigma}_{d}^{\star-1}\left(Y_{i}-\vec{g}\left(\Theta,\alpha\right)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\mathcal{S} & =\mathcal{S}^{\left(h\right)}+\mathcal{S}^{\left(d\right)}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
then our estimates are defined as 
\begin_inset Formula $\hat{\Theta},\hat{\alpha}=\underset{\Theta.\alpha}{\arg\min}\mathcal{S}$
\end_inset

.
 While 
\begin_inset Formula $\alpha$
\end_inset

 has only 
\begin_inset Formula $p$
\end_inset

 parameters, 
\begin_inset Formula $\Theta$
\end_inset

 has 
\begin_inset Formula $m$
\end_inset

 distinct parameters and the joint optimization of 
\begin_inset Formula $\mathcal{S}$
\end_inset

 both on 
\begin_inset Formula $\Theta$
\end_inset

 and 
\begin_inset Formula $\alpha$
\end_inset

 is a computationally-expensive task.
 We address this issue with two measures: First, the optimization is done
 iteratively; Second, since 
\begin_inset Formula $\Theta$
\end_inset

 is not a parameter of interest, it is estimated using a moment estimator.
 Given a set of estimates 
\begin_inset Formula $\hat{\Theta}_{k-1}$
\end_inset

, the estimates of 
\begin_inset Formula $\alpha,\Theta$
\end_inset

 at iteration 
\begin_inset Formula $k$
\end_inset

 are given by: 
\begin_inset Flex TODO Note (inline)
status open

\begin_layout Plain Layout
look for a paper that does iterative MLE optimization and look how he presents
 it (partial? conditional?).
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\hat{\alpha}_{k} & =\underset{\alpha}{\arg\min}\sum_{i\in\mathcal{D}}\left(Y_{i}-\vec{g}\left(\hat{\Theta}_{k-1},\alpha\right)\right)^{t}\bar{\Sigma}_{d}^{\star-1}\left(Y_{i}-\vec{g}\left(\hat{\Theta}_{k-1},\alpha\right)\right),\\
\hat{\Theta}_{k} & =\left(n_{h}+n_{d}\right)^{-1}\left(\sum_{i\in\mathcal{H}}R_{i}+\sum_{i\in\mathcal{D}}g^{-1}\left(R_{i},\hat{\alpha}_{k}\right)\right).
\end{align}

\end_inset


\end_layout

\begin_layout Standard
The starting point of the algorithm, 
\begin_inset Formula $\hat{\Theta}_{0}$
\end_inset

 is calculated solely on the control subjects: 
\begin_inset Formula $\hat{\Theta}_{0}=\bar{R}_{h}$
\end_inset

, with 
\begin_inset Formula $\bar{R}_{h}=n_{h}^{-1}\sum_{i\in\mathcal{H}}R_{i}$
\end_inset

  the average correlation matrix of control subjects.
 Note that the value of 
\begin_inset Formula $T_{eff}$
\end_inset

 wasn't required during the optimization.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Bias of 
\begin_inset Formula $\hat{\Theta},\hat{\alpha}$
\end_inset

 as a Function of 
\begin_inset Formula $n,p$
\end_inset


\begin_inset CommandInset label
LatexCommand label
name "figure-bias-dynamic"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename simulations/bias_function_n.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
two rows - the first is bias, the second is RMSE.
\end_layout

\begin_layout Plain Layout
Write that ARMA doesn't matter - maybe plot but don't show
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Model Inference
\begin_inset CommandInset label
LatexCommand label
name "subsec:Model-Inference"

\end_inset


\end_layout

\begin_layout Standard
The gradient of 
\begin_inset Formula $\mathcal{S}^{\left(d\right)}$
\end_inset

 is 
\begin_inset Formula $\mathbf{J}_{\alpha}g\cdot\tilde{\Sigma}_{d}^{\star-1}\sum_{i\in\mathcal{D}}\left(Y_{i}-\vec{g}\left(\Theta,\alpha\right)\right)$
\end_inset

 where 
\begin_inset Formula $\mathbf{J}_{\alpha}g$
\end_inset

 is the Jacobian matrix of 
\begin_inset Formula $\vec{g}\left(\Theta,\alpha\right)$
\end_inset

 by 
\begin_inset Formula $\alpha$
\end_inset

(
\begin_inset Formula $\left[\mathbf{J}_{\alpha}g\right]_{ij}=\frac{\partial\vec{g}_{i}\left(\Theta,\alpha\right)}{\partial\alpha_{j}}$
\end_inset

), and the gradient of 
\begin_inset Formula $\mathcal{S}^{\left(h\right)}$
\end_inset

 is defined similarly.
 By calculating the minima of 
\begin_inset Formula $\mathcal{S}$
\end_inset

, we are calculating the solution for 
\begin_inset Formula $\nabla_{\alpha}\mathcal{S}=\nabla_{\alpha}\left(\mathcal{S}^{\left(h\right)}+\mathcal{S}^{\left(d\right)}\right)=0$
\end_inset

 whereas 
\begin_inset Formula $E\left[\nabla_{\alpha}\mathcal{S}\right]=0$
\end_inset

.
 
\begin_inset Flex TODO Note (inline)
status open

\begin_layout Plain Layout
do we need to prove this?
\end_layout

\end_inset

 Thus the minimization of 
\begin_inset Formula $\mathcal{S}$
\end_inset

 can be viewed as a solution of General Estimation Equations.
 Using the methodology of the latter 
\begin_inset CommandInset citation
LatexCommand cite
key "liang1986longitudinal"
literal "false"

\end_inset

, we can use the lemma 
\begin_inset Formula $\sqrt{n}\cdot\left(\hat{\alpha}_{gee}-\alpha\right)\overset{d}{\longrightarrow}\mathcal{N}_{p}\left(0,V\left(\hat{\alpha}\right)\right)$
\end_inset

 to conduct inference on our estimates.
 In order to do so, we need to calculate 
\begin_inset Formula $V\left(\hat{\alpha}\right)$
\end_inset

, the variance estimate of 
\begin_inset Formula $\hat{\alpha}$
\end_inset

; 
\begin_inset Formula $V\left(\hat{\alpha}\right)$
\end_inset

 is calculated as a sandwich estimator 
\begin_inset Formula $V\left(\hat{\alpha}\right)=I^{\left(0\right)-1}I^{\left(1\right)}I^{\left(0\right)-1}$
\end_inset

 where 
\begin_inset Formula $I^{\left(0\right)}=I_{h}^{\left(0\right)}+I_{d}^{\left(0\right)}$
\end_inset

 (
\begin_inset Formula $I^{\left(1\right)}$
\end_inset

 defined similarly) .
 These, in turn, are defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
I_{d}^{\left(0\right)} & =n_{d}\cdot\mathbf{J}_{\alpha}g^{t}\cdot\bar{\Sigma}_{d}^{\star-1}\cdot\mathbf{J}_{\alpha}g|_{\alpha=\hat{\alpha}il}\label{eq-gee-var-1}\\
I_{d}^{\left(1\right)} & =n_{d}\cdot\mathbf{J}_{\alpha}g^{t}\cdot\bar{\Sigma}_{d}^{\star-1}\cdot C_{d}\cdot\bar{\Sigma}_{d}^{\star-1}\cdot\mathbf{J}_{\alpha}g|_{\alpha=\hat{\alpha}}\label{eq-gee-var-2}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $C_{d}$
\end_inset

 is an empirical estimate of the covariance of 
\begin_inset Formula $Y_{i}$
\end_inset

 (
\begin_inset Formula $i\in\mathcal{D})$
\end_inset

, computed in the following way:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
C_{d}=n_{eff}^{-1}\sum_{i\in\mathcal{D}}\left(Y_{i}-\vec{g}\left(\Theta,\alpha\right)\right)\left(Y_{i}-\vec{g}\left(\Theta,\alpha\right)\right)^{t}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $I_{h}^{\left(0\right)},I_{h}^{\left(1\right)}$
\end_inset

 are defined similarly with 
\begin_inset Formula $\vec{\Theta}$
\end_inset

, 
\begin_inset Formula $\Sigma_{h}^{\star}$
\end_inset

 replacing 
\begin_inset Formula $\vec{g}\left(\Theta,\alpha\right)$
\end_inset

, 
\begin_inset Formula $\bar{\Sigma}_{d}^{\star}$
\end_inset

.
 In theory, 
\begin_inset Formula $\bar{\Sigma}_{d}^{\star}$
\end_inset

 should be divided by 
\begin_inset Formula $T_{eff}$
\end_inset

 in equations 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq-gee-var-1"
plural "false"
caps "false"
noprefix "false"

\end_inset

,
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq-gee-var-2"
plural "false"
caps "false"
noprefix "false"

\end_inset

; in practice 
\begin_inset Formula $T_{eff}$
\end_inset

 cancels out in the final multiplication of 
\begin_inset Formula $V\left(\hat{\alpha}\right)$
\end_inset

, and so it is omitted.
 This is the first appearance of 
\begin_inset Formula $n_{eff}$
\end_inset

: 
\begin_inset Formula $C_{d}$
\end_inset

 is the empirical covariance matrix of 
\begin_inset Formula $Y_{i}$
\end_inset

 based on 
\begin_inset Formula $n_{d}$
\end_inset

 independent subjects.
 However, the effective number of subjects is lower than 
\begin_inset Formula $n_{d}$
\end_inset

: 
\series bold

\begin_inset Flex TODO Note (inline)
status open

\begin_layout Plain Layout

\series bold
WHY?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Consistency of 
\begin_inset Formula $\hat{V}\left(\hat{\alpha}\right)$
\end_inset

 over 
\begin_inset Formula $n,p$
\end_inset

, Under Weak Null and Time Dependency
\begin_inset CommandInset label
LatexCommand label
name "figure-gee-var-consistency-1"

\end_inset


\end_layout

\end_inset


\begin_inset Graphics
	filename simulations/variance_emp_theo_nonnull.png
	scale 50

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We estimate 
\begin_inset Formula $n_{eff}$
\end_inset

 using Efron's RMS coefficient estimate 
\begin_inset Formula $\hat{\psi}_{d}=\sqrt{\sum_{i<j}\bar{R}_{d,ij}^{2}/{p \choose 2}}$
\end_inset

 and 
\begin_inset Formula $n_{eff}=\frac{n_{d}}{\left(n_{d}-1\right)\hat{\psi}_{d}^{2}+1}$
\end_inset

 ; Finally, we arrive with the following theorem, which in turn allows us
 to conduct inference on the estimates 
\begin_inset Formula $\hat{\alpha}$
\end_inset

 with Z-tests.
\end_layout

\begin_layout Subsubsection*
The Limiting Distribution of Weighted Least Squares Estimates of Correlation
 Matrices
\end_layout

\begin_layout Standard
The estimates derived in chapter 
\begin_inset CommandInset ref
LatexCommand vref
reference "subsec:Model-Estimation"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and the GEE Sandwich Estimates of their variance derived in chapter 
\begin_inset CommandInset ref
LatexCommand vref
reference "subsec:Model-Inference"
plural "false"
caps "false"
noprefix "false"

\end_inset

 have a limiting distribution of 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
V\left(\hat{\alpha}\right)^{-\nicefrac{1}{2}}\left(\hat{\alpha}-\alpha\right)\overset{d}{\longrightarrow}N_{pq}\left(0,I_{pq}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
and particularly, 
\begin_inset Formula $V\left(\hat{\alpha}\right)_{jj}^{-\nicefrac{1}{2}}\left(\hat{\alpha}_{j}-\alpha_{j}\right)\overset{d}{\longrightarrow}0\left(0,1\right)$
\end_inset

 element-wise.
 
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
FWER & FDR
\begin_inset CommandInset label
LatexCommand label
name "figure-fdr"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename simulations/fwer_fdr.png
	scale 50

\end_inset


\end_layout

\end_inset

The number of hypothesis tests is 
\begin_inset Formula $q$
\end_inset

 (the dimension of 
\begin_inset Formula $\alpha$
\end_inset

) that is controlled by the researcher; the selection of 
\begin_inset Formula $q$
\end_inset

 holds a trade-off between the flexibility of the model and the number of
 hypothesis to test.
 Setting a large 
\begin_inset Formula $q$
\end_inset

 eases the severity of the model assumptions on the data, while setting
 a low value minimizes the number of hypothesis.
 For example, by setting 
\begin_inset Formula $q=1$
\end_inset

, one has only 
\begin_inset Formula $p$
\end_inset

 comparisons, while the most simple model of comparing two averaged correlation
 matrices will end up with 
\begin_inset Formula $m\propto\nicefrac{p^{2}}{2}$
\end_inset

 comparisons.
 Increasing the number of hypothesis reduces the statistical power of the
 research, as a result of adjusting the p-values to control the FDR (or
 FWER); In that sense, our model's advantage is it's ability to preserve
 statistical power by reducing the number of comparisons.
 In our working example, we test the alternative hypothesis 
\begin_inset Formula $H_{\left(1\right),i}:\alpha_{i}<1$
\end_inset

 against the null 
\begin_inset Formula $H_{\left(0\right),i}:\alpha_{i}\geq1$
\end_inset

 (since 
\begin_inset Formula $\alpha=1$
\end_inset

 represents the null value of 
\begin_inset Formula $\alpha$
\end_inset

: 
\begin_inset Formula $\Theta_{ij}\cdot\alpha_{i}\alpha_{j}=\Theta_{ij}$
\end_inset

 for 
\begin_inset Formula $\alpha_{i},\alpha_{j}=1$
\end_inset

).
 We can then perform corrections to keep the FDR (or FWER) and FCR only
 on 
\begin_inset Formula $p$
\end_inset

 comparisons, as long as the procedure is robust to the covariance between
 estimates.
\end_layout

\begin_layout Section
Simulations
\end_layout

\begin_layout Standard
In this chapter, we will present the model's performance on simulated data.
 We will start by simulating data based on the model's assumptions - the
 control and diagnosed subjects have an expected correlation matrix of 
\begin_inset Formula $\Theta$
\end_inset

 and 
\begin_inset Formula $g\left(\Theta,\alpha\right)$
\end_inset

, respectively, each matrix based on 
\begin_inset Formula $T$
\end_inset

 independent multivariate measurements.
 We will then relax the assumptions of independent measurements by simulating
 correlation matrices based on time-dependent measurements.
 We will also present robustness simulations - simulating from one link
 function and estimating using another, and simulating from two random correlati
on matrices (with no link function).
 We will also present the model's ability to keep the FWER, Power simulations
 and comparisons, and calculation times.
 We present the algorithms to simulate the data in algorithms 
\begin_inset CommandInset ref
LatexCommand eqref
reference "algo-sample-pars"
plural "false"
caps "false"
noprefix "false"

\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "algo-arma-mvnorm"
plural "false"
caps "false"
noprefix "false"

\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "algo-gen-samples"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Consistency of 
\begin_inset Formula $\hat{V}\left(\hat{\alpha}\right)$
\end_inset

 over 
\begin_inset Formula $n,p$
\end_inset

, Under Strong Null and No Time Dependency
\begin_inset CommandInset label
LatexCommand label
name "figure-gee-var-consistency-2"

\end_inset


\end_layout

\end_inset


\begin_inset Graphics
	filename simulations/variance_emp_theo_null.png
	scale 50

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The first simulations show the bias of the estimates 
\begin_inset Formula $\hat{\Theta},\hat{\alpha}$
\end_inset

.
 In figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "figure-bias-static"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we simulate a random sample of 50 diagnosed and control subjects each,
 with 
\begin_inset Formula $p=50$
\end_inset

.
 40% of the 
\begin_inset Formula $\alpha$
\end_inset

 values are uniformly distributed between 
\begin_inset Formula $\left(0.7,1.1\right)$
\end_inset

 whilst the other are equal to 1.
 The estimates are unbiased for both parameters.
 In figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "figure-bias-dynamic"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we allow the sample size and the dimension 
\begin_inset Formula $p$
\end_inset

 to vary - the sample size varies from 20 to 100 while the dimension varies
 from 20 to 60.
 
\begin_inset Flex TODO Note (inline)
status open

\begin_layout Plain Layout
talk about other parameters
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Effect of 
\begin_inset Formula $\frac{n_{d}}{n_{h}+n_{d}}$
\end_inset

 on
\begin_inset Formula $\hat{V}\left(\text{\hat{\alpha}}\right)$
\end_inset


\begin_inset CommandInset label
LatexCommand label
name "figure-percent-sick"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename simulations/percent_sick_effect.png
	scale 50

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the next simulations, we compare the estimated GEE variance to the bootstrapp
ed empirical variance - for each 
\begin_inset Formula $\Theta,\alpha$
\end_inset

 we simulate 100 samples, each holding a sample size of 
\begin_inset Formula $n_{h}+n_{d}$
\end_inset

.
 Then, we estimate the empirical variance of 
\begin_inset Formula $\hat{\Theta},\hat{\alpha}$
\end_inset

 and compare it the average GEE variance estimate, computed in each simulation.
 In figures 
\begin_inset CommandInset ref
LatexCommand eqref
reference "figure-gee-var-consistency-1"
plural "false"
caps "false"
noprefix "false"

\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "figure-gee-var-consistency-2"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we hold the the proportion of diagnosed subjects (
\begin_inset Formula $\frac{n_{d}}{n_{d}+n_{h}}$
\end_inset

) constant, and allow 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula $p$
\end_inset

 to vary.
 We show that the variance estimate is consistent, for null cases (all 
\begin_inset Formula $\alpha$
\end_inset

-s equal to 1) with no time-dependence, and for non-null cases (some 
\begin_inset Formula $\alpha$
\end_inset

-s don't equal to 1) with time-dependence as well.
 In figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "figure-percent-sick"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we set 
\begin_inset Formula $n=50$
\end_inset

 and 
\begin_inset Formula $p=25$
\end_inset

, but allow the proportion 
\begin_inset Formula $\frac{n_{d}}{n_{d}+n_{h}}$
\end_inset

 to vary.
 Interestingly, but somewhat intuitively, we find that the GEE estimate
 tends to be lower when the proportion is low, in reference to the bootstrapped
 variance.
 However - the GEE estimate always overestimates the variance, keeping the
 FWER under strong control.
 
\begin_inset Flex TODO Note (inline)
status open

\begin_layout Plain Layout
explain why
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Power vs.
 FDR Corrected T-tests
\begin_inset CommandInset label
LatexCommand label
name "figure-power"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename simulations/power_t.png
	scale 50

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "figure-time"

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Computation Times
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename simulations/performance_sim.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
Calculation Time of 
\begin_inset Formula $O\left(p^{4.6}\right)\approx O\left(m^{2.3}\right)$
\end_inset


\end_layout

\end_inset

In figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "figure-fdr"
plural "false"
caps "false"
noprefix "false"

\end_inset

 we examine the control of the FWER (with Holm's correction
\begin_inset CommandInset citation
LatexCommand cite
key "holm1979simple"
literal "false"

\end_inset

) and the control of the FDR (with B-H correction
\begin_inset CommandInset citation
LatexCommand cite
key "benjamini1995controlling"
literal "false"

\end_inset

).
 We test the control in two factors: under the strong null (all null hypothesis
 are true) and the weak null (some alternative hypothesis are true) and
 when the auto-correlation is or is not present.
 Our proposed method keeps the FDR and FWER under control in all cases,
 while the general type-I error (% of rejected nulls out of all nulls) is
 kept under .05.
 In figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "figure-power"
plural "false"
caps "false"
noprefix "false"

\end_inset

 we compare the statistical power of our proposed method versus an ordinary
 series of FDR corrected T-test; For each voxel 
\begin_inset Formula $\left(k,l\right)$
\end_inset

, we conduct T-tests comparing the means of 
\begin_inset Formula $\left\{ \zeta\left(R_{i,kl}\right)\right\} _{i\in\mathcal{H}},\left\{ \zeta\left(R_{j,kl}\right)\right\} _{j\in\mathcal{D}}$
\end_inset

 
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Formula $\zeta$
\end_inset

 is Fisher's Z-Transformation, 
\begin_inset Formula $\zeta\left(r\right)=\frac{1}{2}\ln\left(\frac{1+r}{1-r}\right)$
\end_inset


\end_layout

\end_inset

 and conduct a BH correction on the P-values.
 We then count the number of rejections on voxels having 
\begin_inset Formula $\left\{ k,l:\Lambda_{h,kl}\neq\Lambda_{d,kl}\right\} $
\end_inset

, and the number of columns rejected having 
\begin_inset Formula $\alpha\neq1$
\end_inset

.
 Under the assumption of column-wise effect - our model has more statistical
 power.
 
\end_layout

\begin_layout Standard
We further show the computation time as a function of 
\begin_inset Formula $p$
\end_inset

 in figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "figure-time"
plural "false"
caps "false"
noprefix "false"

\end_inset

 (recall 
\begin_inset Formula $m=\frac{p\left(p-1\right)}{2}\Rightarrow p\approx\sqrt{2m}$
\end_inset

 ).
 Interestingly, we find that the calculation time is approximately 
\begin_inset Formula $O\left(m^{2.3}\right)$
\end_inset

, which is the time needed to invert an 
\begin_inset Formula $m\times m$
\end_inset

 matrix.
\end_layout

\begin_layout Standard
\begin_inset Flex TODO Note (inline)
status open

\begin_layout Plain Layout
robustness - without simulation link : 2 different matrices and difference
 one or 2 columns
\end_layout

\end_inset


\end_layout

\begin_layout Section
Application on Transient Global Amnesia Research Data
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Difference Between Diagnosed and Control Subjects
\begin_inset CommandInset label
LatexCommand label
name "figure-tga-difference"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename tga_analysis/difference_explanatory.png
	scale 50

\end_inset


\begin_inset Graphics
	filename tga_analysis/difference_model.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
Plotting of the differences between diagnosed and control subjects.
 On the left, we examine the empirical differences between average matrices
 (
\begin_inset Formula $\bar{R}_{d}-\bar{R}_{h}$
\end_inset

).
 On the right, we examine the differences estimated by the model (
\begin_inset Formula $\frac{\Theta_{ij}}{1+\alpha_{i}+\alpha_{j}}-\Theta_{ij}=-\frac{\alpha_{i}+\alpha_{j}}{1+\alpha_{i}+\alpha_{j}}\cdot\Theta_{ij}$
\end_inset

)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We inspect the data gathered by 
\begin_inset CommandInset citation
LatexCommand cite
key "peer2014reversible"
literal "false"

\end_inset

; The data consists of 12 patients (aged 
\begin_inset Formula $62.7\pm7.4$
\end_inset

; 5 male) that met the standard clinical criteria for diagnosis of TGA,
 matched by 17 volunteers (aged 
\begin_inset Formula $62.1\pm6.9$
\end_inset

; 8 male) that served as a control group.
 The whole brain network was defined using the Automatic Anatomical Labeling
 (AAL) atlas, which defines 45 brain regions in each cerebral hemisphere
 resulting; 2 columns where omitted from the data as some subject's had
 missing values, resulting with 29 
\begin_inset Formula $88\times88$
\end_inset

 correlation matrices.
 In figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "figure-tga-exploratory"
plural "false"
caps "false"
noprefix "false"

\end_inset

 we plot the two average correlation matrices per each group, and in figure
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "figure-tga-difference"
plural "false"
caps "false"
noprefix "false"

\end_inset

 we plot the difference between two matrices 
\begin_inset Formula $\left(\bar{R}_{d}-\bar{R}_{h}\right)$
\end_inset

.
 We conduct 
\begin_inset Formula $m=3,828$
\end_inset

 T-tests over all correlation coefficients, and the P-values of these tests
 range from 0.0002 to 0.9997; After BH correction, the P-values range from
 0.237 to 1 - and we are unable the reject the global null.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Average Correlation Matrices
\begin_inset CommandInset label
LatexCommand label
name "figure-tga-exploratory"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename tga_analysis/control_explanatory.png
	scale 50

\end_inset


\begin_inset Graphics
	filename tga_analysis/diagnosed_explanatory.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
Exploratory correlation plot of average functional connectivity in control
 subjects (
\begin_inset Formula $\bar{R}_{h}$
\end_inset

, left) and diagnosed subjects (
\begin_inset Formula $\bar{R}_{d}$
\end_inset

, right).
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In order to reduce the number of hypothesis tested, and increase the statistical
 power after the FDR correction, we proceed with applicating the method
 described in this paper on the TGA research data using two different link
 functions and compare both results.
 In figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "figure-tga-model-diff"
plural "false"
caps "false"
noprefix "false"

\end_inset

 we show the estimates of 
\begin_inset Formula $\Lambda_{d}-\Lambda_{h}$
\end_inset

 with the quotient link function 
\begin_inset Formula $g_{ij}=\Theta_{ij}/\left(1+\alpha_{i}+\alpha_{j}\right)$
\end_inset

; While our method underestimates the difference between diagnosed and control
 subjects due the column-wise structure assumed in the model, it allows
 to statistically identify affected regions whilst controlling the FDR.
 In table 
\begin_inset CommandInset ref
LatexCommand eqref
reference "table-tga-results"
plural "false"
caps "false"
noprefix "false"

\end_inset

 we examine the estimates produced by each link function.
 Our method suggests a significant effect in the following regions: 
\begin_inset Flex TODO Note (inline)
status open

\begin_layout Plain Layout
write the regions
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Alpha Effect
\begin_inset CommandInset label
LatexCommand label
name "figure-tga-model-diff"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename tga_analysis/alpha_effect_all.png
	scale 50

\end_inset


\begin_inset Graphics
	filename tga_analysis/alpha_sig.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
The marginal effect of 
\begin_inset Formula $\alpha$
\end_inset

; In the left figure, we show 
\begin_inset Formula $\left[-\frac{\alpha_{i}+\alpha_{j}}{1+\alpha_{i}+\alpha_{j}}\right]_{ij}$
\end_inset

 independently of 
\begin_inset Formula $\Theta_{ij}$
\end_inset

.
 In the right we show only columns with 
\begin_inset Formula $p_{BH}<.05$
\end_inset

, allowing to identify affected regions.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Estimates under Different Link Functions
\begin_inset CommandInset label
LatexCommand label
name "figure-tga-link-estimates"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename simulations/estimates_links.png
	scale 50

\end_inset


\begin_inset Graphics
	filename simulations/zscores_links.png
	scale 50

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Supplementaries
\end_layout

\begin_layout Subsection
Full Results on TGA Data
\end_layout

\begin_layout Subsection
The Delta Method on Correlation Matrices
\end_layout

\begin_layout Subsection
Simulation Algorithms
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Generate Sample Parameters
\begin_inset CommandInset label
LatexCommand label
name "algo-sample-pars"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Parameters:
\series default
 
\begin_inset Formula $p$
\end_inset

, 
\begin_inset Formula $\alpha_{prop}$
\end_inset

, 
\begin_inset Formula $\alpha_{range}$
\end_inset


\end_layout

\begin_layout Enumerate
Generate 
\begin_inset Formula $\Theta$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Enumerate
Generate 
\begin_inset Formula $x\sim\mathcal{MN}_{2p\times p}\left(0,I_{2p},I_{p}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $x\leftarrow x^{t}x$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\Theta\leftarrow diag\left(x\right)^{-\nicefrac{1}{2}}\cdot x\cdot diag\left(x\right)^{-\nicefrac{1}{2}}$
\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
Generate 
\begin_inset Formula $\alpha$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Enumerate
Generate 
\begin_inset Formula $\alpha_{j}\overset{iid}{\sim}Unif\left(\min\left(\alpha_{range}\right),\max\left(\alpha_{range}\right)\right)$
\end_inset

, 
\begin_inset Formula $j=1,...,\alpha_{prop}\cdot p$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha_{p\cdot\alpha_{prop}+1},...,\alpha_{p}\leftarrow1$
\end_inset


\end_layout

\end_deeper
\end_inset


\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Generate ARMA-Based Covariance Matrix
\begin_inset CommandInset label
LatexCommand label
name "algo-arma-mvnorm"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Parameters:
\series default
 
\begin_inset Formula $n\in\mathbb{N}$
\end_inset

, 
\begin_inset Formula $V\in\mathbb{M}_{d}\left(\mathbb{R}\right)$
\end_inset

, 
\begin_inset Formula $a\in\mathbb{R}^{p}$
\end_inset

, 
\begin_inset Formula $m\in\mathbb{R}^{q}$
\end_inset


\end_layout

\begin_layout Enumerate
Generate 
\begin_inset Formula $X\sim\mathcal{MN}_{n\times d}\left(0,I_{n},V\right)$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $Y\leftarrow X$
\end_inset


\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $1<i\leq n$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset Formula $Y_{i,\cdot}\leftarrow\sum_{j=1}^{q}a_{j}X_{i-j,\cdot}$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $Y_{i,\cdot}\leftarrow\sum_{j=1}^{p}m_{j}Y_{i-j,\cdot}$
\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
\begin_inset Formula $Y\leftarrow Y^{t}Y$
\end_inset


\end_layout

\end_inset


\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Generate Samples
\begin_inset CommandInset label
LatexCommand label
name "algo-gen-samples"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Parameters:
\series default
 
\begin_inset Formula $\Lambda,$
\end_inset


\begin_inset Formula $n$
\end_inset

, 
\begin_inset Formula $T$
\end_inset

, 
\begin_inset Formula $a$
\end_inset

, 
\begin_inset Formula $m$
\end_inset


\end_layout

\begin_layout Enumerate
Define 
\begin_inset Formula $S\in\mathbb{M}_{p}\left(\mathbb{R}\right)$
\end_inset

, 
\begin_inset Formula $S_{jj}\overset{iid}{\sim}Unif\left(\sqrt{10},10\right)$
\end_inset

, 
\begin_inset Formula $S_{ij}=0\forall i\neq j$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\Xi\leftarrow S\cdot\Lambda\cdot S$
\end_inset


\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $i\in\left\{ 1,...,n\right\} $
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Enumerate
If 
\begin_inset Formula $a,m$
\end_inset

 are empty:
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset Formula $X_{i}\sim Wishart_{p}\left(\Lambda,T\right)$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $X_{i}\leftarrow diag\left(X_{i}\right)^{-\nicefrac{1}{2}}\cdot X_{i}\cdot diag\left(X_{i}\right)^{-\nicefrac{1}{2}}$
\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
Else:
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset Formula $X_{i}\leftarrow$
\end_inset

[[ref]]
\end_layout

\end_deeper
\end_deeper
\end_inset


\end_layout

\begin_layout Section*
Discussion
\end_layout

\begin_layout Standard
The estimates derived by the GEE solution vary from the ordinary least squares
 solution by the weighting matrix 
\begin_inset Formula $\tilde{\Sigma}^{\star-1}$
\end_inset

.
 OLS estimates and inference will yield misspecified variance estimates
 since the columns of 
\begin_inset Formula $Y_{i}$
\end_inset

 aren't independent.
 The GEE method minimizes a weighted least squares equation where distances
 are inversely weighted by their covariance - in our case, we we use the
 covariance structure of 
\begin_inset Formula $Y_{i}$
\end_inset

 defined in lemma ().
 
\end_layout

\begin_layout Standard
Regarding the estimation of 
\begin_inset Formula $\hat{\Theta}$
\end_inset

, one would suggest using 
\begin_inset Formula $\bar{R}_{h}=n_{h}^{-1}\sum_{i\in\mathcal{H}}R_{i}$
\end_inset

 as it is an unbiased estimator of 
\begin_inset Formula $\Theta$
\end_inset

 (IS IT?); however this estimator isn't efficient - it ignores information
 that can be gained from diagnosed subjects.
  An efficient estimator of 
\begin_inset Formula $\Theta$
\end_inset

 must use the information gained by both sets.
 Since 
\begin_inset Formula $\hat{\Theta}$
\end_inset

 isn't a linear estimator of 
\begin_inset Formula $\Theta$
\end_inset

, we introduce more bias relative to a simple average of the control subjects;
 However the integration of the 
\begin_inset Formula $n_{d}$
\end_inset

 diagnosed subjects increases it's efficiency.
 
\end_layout

\begin_layout Standard
Another note is the sandwich property of 
\begin_inset Formula $V\left(\hat{\alpha}\right)$
\end_inset

.
 Under theoretical assumptions, both 
\begin_inset Formula $\nicefrac{\Sigma_{\bar{R}_{d}}^{\star}}{T_{eff}},\widehat{Cov}_{D}\overset{p}{\longrightarrow}\nicefrac{\Sigma_{\Lambda_{d}}^{\star}}{T_{eff}}$
\end_inset

, yielding 
\begin_inset Formula $\Sigma_{\bar{R}_{d}}^{\star-1}\cdot\widehat{Cov}_{D}\cdot\Sigma_{\bar{R}_{h}}^{\star-1}\overset{p}{\longrightarrow}T_{eff}\cdot\Sigma_{\Lambda_{d}}^{\star}$
\end_inset

.
 The usage of the sandwich estimator helps keep the type-I error even when
 asymptotic assumptions fail to hold.
 
\end_layout

\begin_layout Standard
\begin_inset Formula $\hat{\psi}_{d}$
\end_inset

 is over-estimating the effect of row-wise correlation on the effective
 degrees of freedom 
\begin_inset Flex TODO Note (inline)
status open

\begin_layout Plain Layout
quote Efron
\end_layout

\end_inset

 and causes an over-estimation of the variance of 
\begin_inset Formula $\hat{\alpha}$
\end_inset

, resulting with slightly decreased statistical power.
 Although not an optimal solution, this is a better option than failing
 to control the Type-I error that results with under-estimating the variance.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "bib"
options "plain"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "table-tga-results"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_body
\end_document
